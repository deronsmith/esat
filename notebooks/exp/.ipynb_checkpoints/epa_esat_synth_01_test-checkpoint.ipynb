{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5686853f-4655-4e79-af04-fe24aac1756e",
   "metadata": {},
   "source": [
    "## Environmental Source Apportionment Toolkit (ESAT) Solution Eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b01571c-a954-4399-a913-eeb39cfe91db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770385fe-48ab-47c4-bdbb-50bab6950d05",
   "metadata": {},
   "source": [
    "#### Code Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de6b9e-89a5-4db8-94d4-2226605d9ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esat.data.datahandler import DataHandler\n",
    "from esat.model.sa import SA\n",
    "from esat.model.batch_sa import BatchSA\n",
    "from esat.data.analysis import ModelAnalysis, BatchAnalysis\n",
    "from esat.metrics import q_loss, qr_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfb2b9c-98ee-4482-a0f9-c06b1eeb651f",
   "metadata": {},
   "source": [
    "#### Synthetic Dataset\n",
    "\n",
    "Generate a synthetic dataset where the factor profiles and contributions are pre-determined for model output analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aaf527-dd30-4017-baca-47bbd93b41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "syn_factors = 6\n",
    "syn_features = 40\n",
    "syn_samples = 200\n",
    "\n",
    "rng = np.random.default_rng(seed)\n",
    "syn_factor_profiles = np.zeros(shape=(syn_factors, syn_features))\n",
    "syn_factor_contributions = rng.random(size=(syn_samples, syn_factors)) * 10\n",
    "factor_list = list(range(syn_factors))\n",
    "for i in range(syn_features):\n",
    "    factor_features_n = rng.integers(1, syn_factors, 1)     # Number of factors which will have a non-zero value in the profile for this feature\n",
    "    factor_feature_selected = rng.choice(factor_list, size=factor_features_n, replace=False)     # The specific factors which have a non-zero value in the profile for this feature\n",
    "    for j in factor_feature_selected:\n",
    "        ij_value = rng.random(size=1)\n",
    "        syn_factor_profiles[j, i] = ij_value\n",
    "\n",
    "syn_factor_profiles[syn_factor_profiles == 0.0] = 1e-12\n",
    "\n",
    "syn_data = np.matmul(syn_factor_contributions, syn_factor_profiles)\n",
    "noise = syn_data * np.random.normal(loc=0.1, scale=0.05, size=syn_data.shape)\n",
    "syn_data = np.add(syn_data, noise)\n",
    "\n",
    "syn_unc_p = np.random.normal(loc=0.05, scale=0.01, size=syn_data.shape)\n",
    "syn_uncertainty = syn_data * syn_unc_p\n",
    "syn_uncertainty[syn_uncertainty <= 0.0] = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1330a8-b750-40dd-9503-5c2bfb0e2326",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_columns = [f\"Feature {i}\" for i in range(1, syn_features+1)]\n",
    "syn_input_df = pd.DataFrame(syn_data, columns=syn_columns)\n",
    "syn_uncertainty_df = pd.DataFrame(syn_uncertainty, columns=syn_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f532c5-1e71-4966-8edf-e8f68fa0bd57",
   "metadata": {},
   "source": [
    "#### Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4b336-67a8-4dd1-a758-ed895d933dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_col = \"Date\"                  # the index of the input/uncertainty datasets\n",
    "factors = 5                         # the number of factors\n",
    "method = \"ls-nmf\"                   # \"ls-nmf\", \"ws-nmf\"\n",
    "models = 20                         # the number of models to train\n",
    "init_method = \"col_means\"           # default is column means \"col_means\", \"kmeans\", \"cmeans\"\n",
    "init_norm = True                    # if init_method=kmeans or cmeans, normalize the data prior to clustering.\n",
    "seed = 42                           # random seed for initialization\n",
    "max_iterations = 20000              # the maximum number of iterations for fitting a model\n",
    "converge_delta = 0.1                # convergence criteria for the change in loss, Q\n",
    "converge_n = 10                     # convergence criteria for the number of steps where the loss changes by less than converge_delta\n",
    "verbose = True                      # adds more verbosity to the algorithm workflow on execution.\n",
    "optimized = True                    # use the Rust code if possible\n",
    "parallel = True                     # execute the model training in parallel, multiple models at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef560825-1d60-4ef1-8780-83ebbdd2d683",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_sa = SA(V=syn_input_df.to_numpy(), U=syn_uncertainty_df.to_numpy(), factors=factors, seed=seed, optimized=optimized, parallelized=parallel, verbose=verbose)\n",
    "syn_sa.H = syn_factor_profiles\n",
    "syn_sa.W = syn_factor_contributions\n",
    "syn_sa.WH = syn_data\n",
    "syn_sa.Qrobust = qr_loss(V=syn_sa.V, U=syn_sa.U, W=syn_sa.W, H=syn_sa.H)\n",
    "syn_sa.Qtrue = q_loss(V=syn_sa.V, U=syn_sa.U, W=syn_sa.W, H=syn_sa.H)\n",
    "\n",
    "syn_factor_columns = [f\"Factor {i}\" for i in range(1, syn_factors+1)]\n",
    "syn_profile_df = pd.DataFrame(syn_factor_profiles.T, columns=syn_factor_columns)\n",
    "syn_contribution_df = pd.DataFrame(syn_factor_contributions, columns=syn_factor_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966142b3-bc3d-4e88-bc71-f68d3320d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677562d2-4431-4830-bc3c-f21a39978afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "2%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7b2ed8-10b7-4592-bf48-4226caa26e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curve_x = np.arange(syn_samples)\n",
    "min_y = 1.0\n",
    "max_y = 10.0\n",
    "frequency = 0.3\n",
    "samples_n = 200\n",
    "\n",
    "n_periods = int(1.0/frequency)\n",
    "x_periods = []\n",
    "\n",
    "curve_a = np.linspace(-np.pi, np.pi, int(samples_n/n_periods))\n",
    "curve_x = np.tile(curve_a[0:len(curve_a)-1], n_periods+1)\n",
    "curve_x = curve_x[0:samples_n]\n",
    "curve_y = np.sin(curve_x) * ((max_y-min_y)/2)\n",
    "curve_y = (curve_y + (np.abs(np.min(curve_y)))+min_y)\n",
    "print(curve_y.shape)\n",
    "# curve_x = np.concatenate((np.linspace(-100, 100, int(syn_samples/3)), np.linspace(100, -100, int(syn_samples/3)), np.linspace(-100, 100, int(syn_samples - syn_current_n))), axis=None)\n",
    "# curve_y = min_y + (max_y-min_y)/(1.0 + np.exp(-curve_x))\n",
    "# # curve_x = np.linspace(-np.pi, np.pi, syn_samples)\n",
    "# # curve_y = (np.sin(curve_x) + min_y) * (max_y/2)\n",
    "# curve_y = rng.normal(curve_y, scale=0.5)\n",
    "# syn_factor_contributions[:,0] = curve_y\n",
    "\n",
    "# curve_fig = go.Figure()\n",
    "# for i in range(syn_factors):\n",
    "# contributions_i = syn_factor_contributions[:,i]\n",
    "# curve_fig.add_trace(go.Scatter(x=np.arange(syn_samples), y=curve_y, name=syn_factor_columns[i]))\n",
    "# curve_fig.update_layout(width=1200, height=600)\n",
    "# curve_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d605314-c34a-434d-a178-81b6f6b3766d",
   "metadata": {},
   "source": [
    "#### Load Data\n",
    "Assign the processed data and uncertainty datasets to the variables V and U. These steps will be simplified/streamlined in a future version of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c5901-f26d-4e0e-82a5-52059888de93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler = DataHandler.load_dataframe(input_df=syn_input_df, uncertainty_df=syn_uncertainty_df)\n",
    "V, U = data_handler.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412787cb-62cf-4a86-9a2d-f368030e11db",
   "metadata": {},
   "source": [
    "#### Input/Uncertainty Data Metrics and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d28851-eee3-4682-817e-00ce63e5617b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show the input data metrics, including signal to noise ratio of the data and uncertainty\n",
    "data_handler.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac7440-7f97-4b81-a2ac-6e539f294132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concentration / Uncertainty Scatter plot for specific feature, feature/column specified by index\n",
    "data_handler.plot_data_uncertainty(feature_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c24b313-37ca-412f-b07b-dcd00021773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species Concentration plot comparing features, features/columns specified by index\n",
    "data_handler.plot_feature_data(x_idx=0, y_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964a8c8b-3b57-487c-b7b3-c9f6ca7dad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species Timeseries, a single or list of features/columns specified by index\n",
    "data_handler.plot_feature_timeseries(feature_selection=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018eb975-f9dd-4e73-bf1d-8c5b696e6dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Training multiple models, optional parameters are commented out.\n",
    "sa_models = BatchSA(V=V, U=U, factors=factors, models=models, method=method, seed=seed, max_iter=max_iterations,\n",
    "                    init_method=init_method, init_norm=init_norm,\n",
    "                    converge_delta=converge_delta, converge_n=converge_n, \n",
    "                    parallel=parallel, optimized=optimized,\n",
    "                    verbose=verbose\n",
    "                   )\n",
    "_ = sa_models.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f561829-6c19-4eeb-b8d3-3f83180b9794",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa8298-bd0f-4dea-97f9-43a9971303b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selet the best performing model to review\n",
    "best_model = sa_models.best_model\n",
    "sa_model = sa_models.results[best_model]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335ddfdc-af85-4a19-a442-6eb3bdc9bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform batch model analysis\n",
    "batch_analysis = BatchAnalysis(batch_sa=sa_models)\n",
    "# Plot the loss of the models over iterations\n",
    "batch_analysis.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d4194f-97ac-45bc-80cd-2ca117b93217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss distribution for the batch models\n",
    "batch_analysis.plot_loss_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b187a362-2518-4982-aa3c-bc12c396c65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Model Analysis module\n",
    "model_analysis = ModelAnalysis(datahandler=data_handler, model=sa_model, selected_model=best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d2bff7-b36a-4837-95a9-1ff2bd90c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Analysis shows the scaled residual histogram, along with metrics and distribution curves. The abs_threshold parameter specifies the condition for the returned values of the function call as those residuals which exceed the absolute value of that threshold.\n",
    "abs_threshold = 3.0\n",
    "threshold_residuals = model_analysis.plot_residual_histogram(feature_idx=5, abs_threshold=abs_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13df0f1b-747b-4519-8d74-b30b2cfd3db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"List of Absolute Scaled Residual Greather than: {abs_threshold}. Count: {threshold_residuals.shape[0]}\")\n",
    "threshold_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d33c4-51b4-4c1d-b01e-7b9667638e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model output statistics for the estimated V, including SE: Standard Error metrics, and 3 normal distribution tests of the residuals (KS Normal is used in PMF5)\n",
    "model_analysis.calculate_statistics()\n",
    "model_analysis.statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d23a88-47f5-4692-ba9b-07e8630d5486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model feature observed vs predicted plot with regression and one-to-one lines. Feature/Column specified by index.\n",
    "model_analysis.plot_estimated_observed(feature_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a0280-d275-46d5-973e-48fa55fd51af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model feature timeseries analysis plot showing the observed vs predicted values of the feature, along with the residuals shown below. Feature/column specified by index.\n",
    "model_analysis.plot_estimated_timeseries(feature_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da54785-9c7f-4396-b776-f086612ace02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor profile plot showing the factor sum of concentrations by feature (blue bars), the percentage of the feature as the red dot, and in the bottom plot the normalized contributions by date (values are resampled at a daily timestep for timeseries consistency).\n",
    "# Factor specified by index.\n",
    "model_analysis.plot_factor_profile(factor_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e332d6-75b2-4682-ba27-612dfaf26b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model factor fingerprint specifies the feature percentage of each factor.\n",
    "model_analysis.plot_factor_fingerprints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8bb85b-b48e-4031-b861-d6f6af5ad090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor G-Space plot shows the normalized contributions of one factor vs another factor. Factor specified by index.\n",
    "model_analysis.plot_g_space(factor_1=2, factor_2=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e299347b-a88c-432b-a68f-270ba15f35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor contribution pie chart shows the percentage of factor contributions for the specified feature, and the corresponding normalized contribution of each factor for that feature (bottom plot). Feature specified by index.\n",
    "model_analysis.plot_factor_contributions(feature_idx=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75faa239-e876-4da2-a442-20187d60f2b4",
   "metadata": {},
   "source": [
    "### Compare to Synthetic Data\n",
    "\n",
    "Compare the set of batch models to the original synthetic factor data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eafe023-e783-4c17-bf08-7242f375cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.factor_comparison import FactorCompare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e395e55c-670d-4101-bd62-0cc54f43ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_comp = FactorCompare(input_df=data_handler.input_data, uncertainty_df=data_handler.uncertainty_data, base_profile_df=syn_profile_df, base_contribution_df=syn_contribution_df, batch_sa=sa_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df1d62c-a7fa-4298-a775-52cdb0ae105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_comp.compare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012cc322-22ce-4c07-a617-8b2b8d83032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29ca7c6-5d7f-4a94-bddd-ee11d3c63450",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_comp.best_factor_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d62c33-afe0-4104-937e-a40c340266ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = px.colors.sample_colorscale(\"plasma\", [n/(factors -1) for n in range(factors)])\n",
    "r_color_map = px.colors.sample_colorscale(\"jet\", [n/(100 -1) for n in range(100)])\n",
    "\n",
    "c_model = sa_models.results[factor_comp.best_model]\n",
    "syn_H = syn_factor_profiles\n",
    "norm_syn_H = 100 * (syn_H / syn_H.sum(axis=0))\n",
    "\n",
    "_H = sa_models.results[factor_comp.best_model].H\n",
    "norm_H = 100 * (_H / _H.sum(axis=0))\n",
    "\n",
    "syn_W = syn_factor_contributions\n",
    "norm_syn_W = 100 * (syn_W / syn_W.sum(axis=0))\n",
    "_W = sa_models.results[factor_comp.best_model].W\n",
    "norm_W = 100 * (_W / _W.sum(axis=0))\n",
    "\n",
    "factor_n = min(len(factor_comp.sa_factors), len(factor_comp.base_factors))\n",
    "# print(f\"Base factors: {len(factor_comp.base_factors)}, SA factors: {len(factor_comp.sa_factors)}. Factor N: {factor_n}\")\n",
    "if not factor_comp.base_k:\n",
    "    subplot_titles = [f\"Synthetic Factor {i} : Modelled {factor_comp.factor_map[i-1]}\" for i in range(1, factor_n+1)]\n",
    "else:\n",
    "    subplot_titles = [f\"Modelled Factor {i} : Synthetic {factor_comp.factor_map[i-1]}\" for i in range(1, factor_n+1)]\n",
    "print(f\"Factor Map: {factor_comp.factor_map}\")\n",
    "print(f\"Profile r2: {factor_comp.best_factor_r}\")\n",
    "print(f\"Contribution r2: {factor_comp.best_contribution_r}\")\n",
    "for i in range(1, factor_n+1):\n",
    "    map_i = int(factor_comp.factor_map[i-1].split(\" \")[1])\n",
    "    if not factor_comp.base_k:\n",
    "        syn_i = i - 1\n",
    "        mod_i = map_i - 1\n",
    "        # i_r2 = factor_comp.best_factor_r[i-1]\n",
    "        # i_r2_con = factor_comp.best_contribution_r[i-1]\n",
    "    else:\n",
    "        syn_i = map_i - 1\n",
    "        mod_i = i - 1\n",
    "    i_r2 = factor_comp.best_factor_r[i-1]\n",
    "    i_r2_con = factor_comp.best_contribution_r[i-1]\n",
    "    print(f\"i: {i}, syn_i: {syn_i}, mod_i: {mod_i}, i_r2: {i_r2}, i_r2_con: {i_r2_con}\")\n",
    "    label = (subplot_titles[i-1] + \" - R2: \" + str(round(i_r2,4)), subplot_titles[i-1] + \" - R2: \" + str(round(i_r2_con,4)), \"\", \"\",)\n",
    "    h_fig = make_subplots(rows=2, cols=2, subplot_titles=label, vertical_spacing=0.01, row_heights=[0.6, 0.4])\n",
    "    h_fig.add_trace(go.Bar(name=f\"Synthetic Profile f{syn_i+1}\", x=data_handler.features, y=norm_syn_H[syn_i], marker_color=\"black\"), row=1, col=1)\n",
    "    h_fig.add_trace(go.Bar(name=f\"Modelled Profile f{mod_i+1}\", x=data_handler.features, y=norm_H[mod_i], marker_color=\"green\"), row=1, col=1)\n",
    "    h_fig.add_trace(go.Bar(name=\"\", x=data_handler.features, y=norm_syn_H[syn_i]- norm_H[mod_i], marker_color=\"blue\", showlegend=False), row=2, col=1)\n",
    "    h_fig.add_trace(go.Scatter(name=f\"Synthetic Contribution f{syn_i+1}\", x=data_handler.input_data_df.index, y=norm_syn_W[:,syn_i], line_color=\"black\"), row=1, col=2)\n",
    "    h_fig.add_trace(go.Scatter(name=f\"Model Contribution f{mod_i+1}\", x=data_handler.input_data_df.index, y=norm_W[:,mod_i], line_color=\"green\"), row=1, col=2)\n",
    "    h_fig.add_trace(go.Scatter(name=\"\", x=data_handler.input_data_df.index, y=norm_syn_W[:,syn_i]- norm_W[:,mod_i], marker_color=\"blue\", showlegend=False), row=2, col=2)\n",
    "    h_fig.update_yaxes(title_text=\"Synthetic Profile\", row=1, col=1, title_standoff=3)\n",
    "    h_fig.update_yaxes(title_text=\"Difference\", row=2, col=1)\n",
    "    h_fig.update_yaxes(title_text=\"Scaled Concentrations\", row=1, col=2)\n",
    "    h_fig.update_xaxes(row=1, showticklabels=False)\n",
    "    h_fig.update_yaxes(row=2, col=2, title_text=\"Residuals\")\n",
    "    h_fig.update_yaxes(row=2, col=1, range=[-50, 50])\n",
    "    h_fig.update_layout(title_text=f\"Mapped Factor Comparison - Model: {factor_comp.best_model+1}\", width=1600, height=800, hovermode='x', showlegend=True)\n",
    "    h_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7029904a-9220-45e7-afc2-74060d2a9280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0fec89-0a34-45d9-9c04-4d43d201bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_H = syn_factor_profiles\n",
    "syn_W = syn_factor_contributions\n",
    "\n",
    "_H = sa_models.results[factor_comp.best_model].H\n",
    "_W = sa_models.results[factor_comp.best_model].W\n",
    "\n",
    "syn_matrices = []\n",
    "pred_matrices = []\n",
    "for f in range(factors):\n",
    "    f_sW = syn_W[:, f]\n",
    "    f_sW = np.reshape(f_sW, (len(f_sW), 1))\n",
    "    f_sH = [syn_H[f]]\n",
    "    f_sWH = np.matmul(f_sW, f_sH)\n",
    "    syn_matrices.append(f_sWH)\n",
    "\n",
    "    f_pW = _W[:, f]\n",
    "    f_pW = np.reshape(f_pW, (len(f_pW), 1))\n",
    "    f_pH = [_H[f]]\n",
    "    f_pWH = np.matmul(f_pW, f_pH)\n",
    "    pred_matrices.append(f_pWH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f49f9b8-f598-4dcf-a25a-4743f97eefc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(syn_input_df.index)\n",
    "y = list(syn_input_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac81fc-b9c0-49fe-9e3f-346306fb0984",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_i = 3\n",
    "feature_i = 1\n",
    "syn_i = syn_matrices[factor_i][:,feature_i] / syn_matrices[factor_i][:,feature_i].sum()\n",
    "pred_i = pred_matrices[factor_i][:,feature_i] / pred_matrices[factor_i][:,feature_i].sum()\n",
    "residual_i = syn_i - pred_i\n",
    "y_max = max(np.max(syn_matrices[factor_i]), np.max(pred_matrices[factor_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feeb7fe-0447-420d-b506-9db1d19d750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_fig = go.Figure()\n",
    "conc_fig.add_trace(go.Scatter(x=x, y=syn_i, name=\"Synthetic Data\"))\n",
    "conc_fig.add_trace(go.Scatter(x=x, y=pred_i, name=\"Predicted Data\"))\n",
    "# conc_fig.add_trace(go.Scatter(x=x, y=residual_i, name=\"Residuals\"))\n",
    "conc_fig.update_layout(width=1200, height=800, title_text=f\"Factor: {factor_i+1}\", hovermode='x unified')\n",
    "conc_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d396279a-33f4-4c8a-8dc0-7ccd6744b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d549354f-c4f3-489e-9d11-7396001e16ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product, permutations, combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479ee040-8d0f-46c2-950a-bc93f34dec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_factors = [f\"Factor {i+1}\" for i in range(6)]\n",
    "model_factors = [f\"Factor {i+1}\" for i in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b777e-5c7e-49a0-9919-892a182f14d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(base_factors) >= len(model_factors):\n",
    "    all_permutations = list(permutations(base_factors, len(model_factors)))\n",
    "    print(\"Base model has the same or more factors\")\n",
    "else:\n",
    "    all_permutations = list(permutations(model_factors, len(base_factors)))\n",
    "    print(\"ESAT model has more factors\")\n",
    "len(all_permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61deb8dd-129a-4bc7-ba71-f9428cb6e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01365150-6811-4270-96f4-743fd9b64276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
