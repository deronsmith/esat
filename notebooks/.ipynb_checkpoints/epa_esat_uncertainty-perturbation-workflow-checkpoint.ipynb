{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5686853f-4655-4e79-af04-fe24aac1756e",
   "metadata": {},
   "source": [
    "## ESAT Uncertainty Perturbation Workflow\n",
    "\n",
    "This notebook implements an uncertainty perturbation workflow for model evaluation.\n",
    "\n",
    "Here the Factor Catalog is derived by evaluating the correlation between factor Ws."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206ac55f-9259-4ce1-b87e-3302d2ed00f9",
   "metadata": {},
   "source": [
    "#### Code Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9de6b9e-89a5-4db8-94d4-2226605d9ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from tqdm.notebook import trange, tqdm, tnrange\n",
    "from plotly.subplots import make_subplots\n",
    "from esat.data.datahandler import DataHandler\n",
    "from esat.model.sa import SA\n",
    "from esat.model.batch_sa import BatchSA\n",
    "from esat.data.analysis import ModelAnalysis, BatchAnalysis\n",
    "from esat.error.bootstrap import Bootstrap\n",
    "from esat_eval.simulator import Simulator\n",
    "from esat_eval.factor_comparison import FactorCompare\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47e80dbc-702b-4fca-b800-0660033a251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synethic dataset parameter value ranges\n",
    "syn_factors_min = 3\n",
    "syn_factors_max = 8\n",
    "\n",
    "syn_features_min = 15\n",
    "syn_features_max = 45\n",
    "\n",
    "syn_samples_min = 200\n",
    "syn_samples_max = 1000\n",
    "\n",
    "outliers = True\n",
    "outliers_p_min = 0.05\n",
    "outliers_p_max = 0.1\n",
    "outliers_mag_min = 1.1\n",
    "outliers_mag_max = 2\n",
    "\n",
    "noise_mean_min = 0.05\n",
    "noise_mean_max = 0.15\n",
    "noise_scale = 0.01\n",
    "\n",
    "uncertainty_mean_min = 0.05\n",
    "uncertainty_mean_max = 0.15\n",
    "uncertainty_scale = 0.01\n",
    "\n",
    "contr_curve_min_range = [0.0, 1.0]\n",
    "contr_curve_max_range = [2.0, 5.0]\n",
    "contr_curve_scale_range = [0.1, 0.5]\n",
    "\n",
    "random_seed = 337\n",
    "k_coef = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2408991-45a6-4a5c-ac14-388f79cbab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "372a6a6a-612a-4d00-a3ae-be12aecb0e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the simulator with the above parameters\n",
    "def generate_synthetic_data(true_factor):\n",
    "    n_features = rng.integers(low=syn_features_min, high=syn_features_max, size=1)[0]\n",
    "    n_samples = rng.integers(low=syn_samples_min, high=syn_samples_max, size=1)[0]\n",
    "    i_outlier_p = round(rng.uniform(low=outliers_p_min, high=outliers_p_max, size=1)[0], 2)\n",
    "    i_outlier_mag = round(rng.uniform(low=outliers_mag_min, high=outliers_mag_max, size=1)[0], 2)\n",
    "    contribution_max = round(rng.uniform(low=1.0, high=10.0, size=1)[0], 2)\n",
    "    print(f\"True Factors: {true_factor}, Features: {n_features}, Samples: {n_samples}, Outliers %: {i_outlier_p}, Outliers Magnitude: {i_outlier_mag}, Contribution Max: {contribution_max}\")\n",
    "    simulator = Simulator(seed=rng.integers(low=0, high=10, size=1)[0],\n",
    "                          factors_n=true_factor,\n",
    "                          features_n=n_features,\n",
    "                          samples_n=n_samples,\n",
    "                          outliers=outliers,\n",
    "                          outlier_p=i_outlier_p,\n",
    "                          outlier_mag=i_outlier_mag,\n",
    "                          contribution_max=contribution_max,\n",
    "                          noise_mean_min=noise_mean_min,\n",
    "                          noise_mean_max=noise_mean_max,\n",
    "                          noise_scale=noise_scale,\n",
    "                          uncertainty_mean_min=uncertainty_mean_min,\n",
    "                          uncertainty_mean_max=uncertainty_mean_max,\n",
    "                          uncertainty_scale=uncertainty_scale,\n",
    "                          verbose=False\n",
    "                         )\n",
    "    curved_factors_count = rng.integers(low=0, high=true_factor, size=1)[0]\n",
    "    curved_factor_list = rng.choice(list(range(true_factor)), size=curved_factors_count, replace=False)\n",
    "    for c_i in curved_factor_list:\n",
    "        # parameters not used by the curve type are ignored\n",
    "        i_curve_type = rng.choice(['uniform', 'decreasing', 'increasing', 'logistic', 'periodic'], size=1)[0]\n",
    "        i_curve_min = rng.uniform(low=contr_curve_min_range[0], high=contr_curve_min_range[1], size=1)[0]\n",
    "        i_curve_max = rng.uniform(low=contr_curve_max_range[0], high=contr_curve_max_range[1], size=1)[0]\n",
    "        i_curve_scale = rng.uniform(low=contr_curve_scale_range[0], high=contr_curve_scale_range[1], size=1)[0]\n",
    "        i_curve_frequency = rng.uniform(low=0.1, high=0.9, size=1)[0]\n",
    "        \n",
    "        # To keep all as uniform comment out the line below\n",
    "        # simulator.update_contribution(factor_i=c_i, curve_type=i_curve_type, scale=i_curve_scale, frequency=i_curve_frequency, minimum=i_curve_min, maximum=i_curve_max)\n",
    "    \n",
    "    syn_input_df, syn_uncertainty_df = simulator.get_data()\n",
    "    data_handler = DataHandler.load_dataframe(input_df=syn_input_df, uncertainty_df=syn_uncertainty_df)\n",
    "    data_handler.metrics\n",
    "    V, U = data_handler.get_data()\n",
    "    return V, U\n",
    "\n",
    "def perturb_uncertainty(u, _rng, perturb_p = 0.25, sigma = 0.25):\n",
    "    i_u = copy.copy(u)\n",
    "    if isinstance(perturb_p, float):\n",
    "        perturb_p = [perturb_p for i in range(u.shape[1])]\n",
    "    elif isinstance(perturb_p, list) and len(perturb_p) != u.shape[1]:\n",
    "        perturb_p = [perturb_p[0] for i in range(u.shape[1])]\n",
    "    if isinstance(sigma, float):\n",
    "        sigma = [sigma for i in range(u.shape[1])]\n",
    "    elif isinstance(sigma, list) and len(sigma) != u.shape[1]:\n",
    "        sigma = [sigma[0] for i in range(u.shape[1])]\n",
    "    for i, _p in enumerate(perturb_p):\n",
    "        i_mask = _rng.random(size=u[:,i].shape) > _p\n",
    "        i_mean = 1.0\n",
    "        i_logn = _rng.lognormal(i_mean, sigma[i], size=u[:,i].shape)\n",
    "        ij_u = i_u[:,i]\n",
    "        ij_u = ij_u * i_logn\n",
    "        ij_u[i_mask] = ij_u[i_mask]\n",
    "        ij_u[ij_u <= 0.0] = 1e-12\n",
    "        i_u[:,i] = ij_u\n",
    "    return i_u\n",
    "\n",
    "\n",
    "def run_perturbation(v, u, factors, random_seed, u_collection = None, perturb_p = 1.0, sigma = 0.33, sa_model=None, models=10, max_iter=10000, converge_n=50, converge_delta=0.01, threshold: float=0.9, pg_leave=True, verbose=False):\n",
    "    # Runs a perturbation input batch instance\n",
    "    # Steps:\n",
    "    # 1. Create a SA instance using the provided iV, iU and true_k for the data and factor count (if one is not provided).\n",
    "    # 2. Using a lognormal std (sigma) and % instance change (perturb_p) for the uncertainty:\n",
    "    #    a. Select perturb_p number of indecies from the uncertainty data matrix and change those values by a random selection from a lognormal distribution with mean=1 and sigma/std=the provided valude (default=0.25)\n",
    "    #    b. Use a provided collection of pre-defiend uncertainty matrices\n",
    "    # 3. With the perturbed uncertainty rerun the model using the base model H matrix.\n",
    "    # 4. Repeat for n number of models\n",
    "    # 5. Evaluate the results from all the perturb model profiles and concentrations, the ones that mapped (had a correlation above the threhsold) and provide the range of values for the factors.\n",
    "    rng = np.random.default_rng(seed=random_seed)\n",
    "    # step 1\n",
    "    if sa_model is None:\n",
    "        sa_model = SA(V=v, U=u, factors=factors, seed=random_seed, verbose=verbose, method=\"ls-nmf\")\n",
    "        sa_model.initialize()\n",
    "        sa_model.train(max_iter=max_iter, converge_delta=converge_delta, converge_n=converge_n)\n",
    "\n",
    "    base_mean_W = np.mean(sa_model.W, axis=0)[0]\n",
    "    base_mass_matrix = (base_mean_W*sa_model.H)/np.sum(base_mean_W*sa_model.H)    # base mass matrix\n",
    "    \n",
    "    perturb_results = {\n",
    "        \"k\": factors,\n",
    "        \"seed\": random_seed,\n",
    "        \"base model\": sa_model,\n",
    "        \"perturb %\": perturb_p,\n",
    "        \"perturb sigma\": sigma,\n",
    "        \"perturb results\": {}\n",
    "    }\n",
    "    \n",
    "    for i in tnrange(models, desc=\"Running Perturbations on base model\", leave=pg_leave):\n",
    "        if u_collection is None:\n",
    "            i_u = perturb_uncertainty(u=u, perturb_p=perturb_p, sigma=sigma, _rng=rng)\n",
    "        elif i > len(u_collection):\n",
    "            i_u = perturb_uncertainty(u=u, perturb_p=perturb_p, sigma=sigma, _rng=rng)\n",
    "        else:\n",
    "            i_u = u_collection[i]\n",
    "            \n",
    "        i_sa_model = SA(v, U=i_u, factors=factors, seed=random_seed, verbose=verbose, method=\"ls-nmf\")\n",
    "        i_sa_model.initialize(H=sa_model.H, W=sa_model.W)\n",
    "        i_sa_model.train(max_iter=max_iter, converge_delta=converge_delta, converge_n=converge_n)\n",
    "\n",
    "        i_results = {\n",
    "            \"model\": copy.copy(i_sa_model),\n",
    "            \"corr\": [],\n",
    "            \"corr_mapping\": [],\n",
    "            \"all_corr\": [],\n",
    "            \"raae\": [],\n",
    "            \"raae_mapping\": [],\n",
    "            \"all_raae\": [],\n",
    "            \"emc\": [],\n",
    "            \"emc_mapping\": [],\n",
    "            \"all_emc\": []\n",
    "        }\n",
    "        n = 1/sa_model.W[:,0].shape[0]\n",
    "\n",
    "        i_W_mean = np.mean(i_sa_model.W, axis=0)[0]\n",
    "        i_mass_matrix = (i_W_mean*i_sa_model.H)/np.sum(i_W_mean*i_sa_model.H)   # perturbed mass matrix\n",
    "        \n",
    "        for j in range(factors):\n",
    "            j_W = sa_model.W[:,j]      # Base model W column j (factor contribution)\n",
    "            j_H = sa_model.H[j]        # Base model H row j (factor profile)\n",
    "\n",
    "            # Tacking results of equation 4\n",
    "            j_r2 = 0.0\n",
    "            r2_best = -1\n",
    "            all_corr = []\n",
    "\n",
    "            # Tracking results of equation 5\n",
    "            j_raae = float(\"inf\")\n",
    "            raae_best = -1\n",
    "            all_raae = []\n",
    "\n",
    "            # Tracking results of equation 7\n",
    "            j_emc = 0.0\n",
    "            best_emc = -1\n",
    "            all_emc = []\n",
    "            \n",
    "            for k in range(factors):\n",
    "                k_W = i_sa_model.W[:,k]    # Perturbed model i, W column j (perturbed factor contribution j)\n",
    "                jk_r2 = FactorCompare.calculate_correlation(factor1=j_W.flatten(), factor2=k_W.flatten())    # Equation 4\n",
    "                jk_raae = (np.sum(np.abs(k_W - j_W))*n)/(np.sum(j_W)*n)                                      # Equation 5\n",
    "                jk_emc = FactorCompare.calculate_correlation(factor1=base_mass_matrix[j], factor2= i_mass_matrix[k]) # Equation 7\n",
    "                \n",
    "                if jk_r2 > j_r2:\n",
    "                    r2_best = k \n",
    "                    j_r2 = jk_r2\n",
    "                if jk_raae < j_raae:\n",
    "                    j_raae = jk_raae\n",
    "                    raae_best = k\n",
    "                if jk_emc > j_emc:\n",
    "                    j_emc = jk_emc\n",
    "                    best_emc = k\n",
    "                all_corr.append(jk_r2)\n",
    "                all_raae.append(jk_raae)\n",
    "                all_emc.append(jk_emc)\n",
    "            i_results[\"corr\"].append(j_r2)\n",
    "            i_results[\"corr_mapping\"].append(r2_best)\n",
    "            i_results[\"all_corr\"].append(all_corr)\n",
    "            i_results[\"raae\"].append(j_raae)\n",
    "            i_results[\"raae_mapping\"].append(raae_best)\n",
    "            i_results[\"all_raae\"].append(all_raae)\n",
    "            i_results[\"emc\"].append(j_emc)\n",
    "            i_results[\"emc_mapping\"].append(best_emc)\n",
    "            i_results[\"all_emc\"].append(all_emc)\n",
    "        perturb_results[\"perturb results\"][i] = i_results\n",
    "    return perturb_results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a89726-42b6-4aeb-88d2-6d8b71c02737",
   "metadata": {},
   "source": [
    "## Single Perturbation Instance\n",
    "\n",
    "A single instance of the run_perturbation function is called. This will create a single SA instance to use as the base model with n_models being the number of perturbed instances to make (each independent of each other) for that single base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1728e8e8-cd9a-4a68-a5c1-2ab827ca237a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Factors: 8, Features: 24, Samples: 222, Outliers %: 0.06, Outliers Magnitude: 1.8, Contribution Max: 9.26\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 70.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "true_k = 8\n",
    "iV, iU = generate_synthetic_data(true_factor=true_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcb14e0-00c4-423f-bc8b-6631eea7366f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-Nov-24 15:37:53 - R - Model: -1, Seed: 3, Q(true): 12048.6212, MSE(true): 2.2614, Q(robust): 11055.8545, MSE(robust): 2.075, Steps: 29264/40000, Converged: True, Runtime: 11.19 sec\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6afa692ff6f64cb7a0a3137dc5e8d2c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Perturbations on base model:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-Nov-24 15:38:18 - R - Model: -1, Seed: 3, Q(true): 2221.8816, MSE(true): 0.417, Q(robust): 2220.7022, MSE(robust): 0.4168, Steps: 39999/40000, Converged: False, Runtime: 24.28 sec\n",
      "12-Nov-24 15:38:34 - R - Model: -1, Seed: 3, Q(true): 2434.4634, MSE(true): 0.4569, Q(robust): 2424.55, MSE(robust): 0.4551, Steps: 30317/40000, Converged: True, Runtime: 15.96 sec\n",
      "12-Nov-24 15:38:51 - R - Model: -1, Seed: 3, Q(true): 2158.7157, MSE(true): 0.4052, Q(robust): 2144.8501, MSE(robust): 0.4026, Steps: 31244/40000, Converged: True, Runtime: 17.67 sec\n",
      "12-Nov-24 15:39:07 - R - Model: -1, Seed: 3, Q(true): 2533.076, MSE(true): 0.4754, Q(robust): 2521.7525, MSE(robust): 0.4733, Steps: 28285/40000, Converged: True, Runtime: 15.65 sec\n",
      "12-Nov-24 15:39:20 - R - Model: -1, Seed: 3, Q(true): 2397.739, MSE(true): 0.45, Q(robust): 2383.185, MSE(robust): 0.4473, Steps: 24789/40000, Converged: True, Runtime: 13.1 sec\n",
      "12-Nov-24 15:39:41 - R - Model: -1, Seed: 3, Q(true): 2097.062, MSE(true): 0.3936, Q(robust): 2085.6041, MSE(robust): 0.3914, Steps: 34965/40000, Converged: True, Runtime: 20.57 sec\n"
     ]
    }
   ],
   "source": [
    "estimate_k = 8\n",
    "n_models = 10\n",
    "threshold = 0.9\n",
    "\n",
    "perturb_p = 1.0\n",
    "perturb_sigma = 0.75\n",
    "\n",
    "batch_results0 = run_perturbation(factors=estimate_k, v=iV, u=iU, random_seed=random_seed, perturb_p=perturb_p, sigma=perturb_sigma, models=n_models, max_iter=40000, converge_n=100, converge_delta=0.001, threshold=threshold, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2d2874-0954-45da-bad9-083a4aebd2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96eb851e-7cba-46ec-ac6c-432b21aef3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Factor</th>\n",
       "      <th>R2</th>\n",
       "      <th>RAAE</th>\n",
       "      <th>EMC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Factor       R2     RAAE      EMC\n",
       "0       0 100.0000 100.0000 100.0000\n",
       "1       1 100.0000 100.0000 100.0000\n",
       "2       2 100.0000 100.0000 100.0000\n",
       "3       3 100.0000 100.0000 100.0000\n",
       "4       4 100.0000 100.0000 100.0000\n",
       "5       5 100.0000 100.0000 100.0000\n",
       "6       6 100.0000 100.0000 100.0000\n",
       "7       7 100.0000 100.0000 100.0000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metrics\n",
    "# Factor mapping (what percentage of perturbed model factors map to the base model factors, using corr(W), RAAE or EMC)\n",
    "# Factor profile ranges (among mapped perturbed model factors)\n",
    "# Factor mean contribution ranges (among mapped pertrubed model factors)\n",
    "n_factors = estimate_k\n",
    "corr_mapping = [0] * n_factors\n",
    "raae_mapping = [0] * n_factors\n",
    "emc_mapping = [0] * n_factors\n",
    "for i, p_model in batch_results0[\"perturb results\"].items():\n",
    "    cmap_dif = np.subtract(p_model[\"corr_mapping\"], list(range(n_factors)))\n",
    "    raae_dif = np.subtract(p_model[\"raae_mapping\"], list(range(n_factors)))\n",
    "    emc_dif = np.subtract(p_model[\"emc_mapping\"], list(range(n_factors)))\n",
    "    for j in range(n_factors):\n",
    "        if cmap_dif[j] == 0:\n",
    "            corr_mapping[j] += 1\n",
    "        if raae_dif[j] == 0:\n",
    "            raae_mapping[j] += 1\n",
    "        if emc_dif[j] == 0:\n",
    "            emc_mapping[j] += 1\n",
    "mapping_df = pd.DataFrame(data=\n",
    "                          {\n",
    "                              \"Factor\": list(range(n_factors)), \n",
    "                              \"R2\": np.round(100 * np.array(corr_mapping)/n_models, 2), \n",
    "                              \"RAAE\": np.round(100 * np.array(raae_mapping)/n_models, 2), \n",
    "                              \"EMC\": np.round(100 * np.array(emc_mapping)/n_models, 2)\n",
    "                          }\n",
    "                         )\n",
    "mapping_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efef0cc4-0061-42a3-a4d9-9d896c0f9bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Factor 0</th>\n",
       "      <th>Factor 1</th>\n",
       "      <th>Factor 2</th>\n",
       "      <th>Factor 3</th>\n",
       "      <th>Factor 4</th>\n",
       "      <th>Factor 5</th>\n",
       "      <th>Factor 6</th>\n",
       "      <th>Factor 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Base Factor 0</th>\n",
       "      <td>0.9526</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0457</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 2</th>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8330</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 3</th>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8240</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 4</th>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.7422</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 5</th>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 6</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9349</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 7</th>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.9579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Factor 0  Factor 1  Factor 2  Factor 3  Factor 4  Factor 5  \\\n",
       "Base Factor 0    0.9526    0.0000    0.0011    0.0457    0.0073    0.0065   \n",
       "Base Factor 1    0.0000    0.8667    0.0007    0.0470    0.0009    0.0021   \n",
       "Base Factor 2    0.0033    0.0000    0.8330    0.0013    0.0049    0.0000   \n",
       "Base Factor 3    0.0330    0.0489    0.0000    0.8240    0.0058    0.0046   \n",
       "Base Factor 4    0.0009    0.0162    0.0014    0.0028    0.7422    0.0070   \n",
       "Base Factor 5    0.0063    0.0020    0.0035    0.0013    0.0129    0.8704   \n",
       "Base Factor 6    0.0002    0.0075    0.0063    0.0037    0.0104    0.0000   \n",
       "Base Factor 7    0.0152    0.0015    0.0086    0.0186    0.0130    0.0016   \n",
       "\n",
       "               Factor 6  Factor 7  \n",
       "Base Factor 0    0.0022    0.0132  \n",
       "Base Factor 1    0.0149    0.0061  \n",
       "Base Factor 2    0.0043    0.0038  \n",
       "Base Factor 3    0.0038    0.0004  \n",
       "Base Factor 4    0.0074    0.0036  \n",
       "Base Factor 5    0.0027    0.0030  \n",
       "Base Factor 6    0.9349    0.0001  \n",
       "Base Factor 7    0.0008    0.9579  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_columns = [f\"Factor {i}\" for i in range(n_factors)]\n",
    "df_index = [f\"Base Factor {i}\" for i in range(n_factors)]\n",
    "corr_df = pd.DataFrame(data=np.array(batch_results0[\"perturb results\"][0][\"all_corr\"]), columns=df_columns, index=df_index)\n",
    "print(\"Correlation Matrix\")\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a129c799-dd6a-42b4-b4c9-d4da03dcc903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAAE Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Factor 0</th>\n",
       "      <th>Factor 1</th>\n",
       "      <th>Factor 2</th>\n",
       "      <th>Factor 3</th>\n",
       "      <th>Factor 4</th>\n",
       "      <th>Factor 5</th>\n",
       "      <th>Factor 6</th>\n",
       "      <th>Factor 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Base Factor 0</th>\n",
       "      <td>0.0816</td>\n",
       "      <td>0.6774</td>\n",
       "      <td>0.6529</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>0.6940</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.6273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 1</th>\n",
       "      <td>1.2915</td>\n",
       "      <td>0.1569</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.5875</td>\n",
       "      <td>0.6581</td>\n",
       "      <td>1.0525</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>0.7938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 2</th>\n",
       "      <td>1.1962</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.6418</td>\n",
       "      <td>0.6491</td>\n",
       "      <td>1.0343</td>\n",
       "      <td>0.7871</td>\n",
       "      <td>0.7483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 3</th>\n",
       "      <td>1.6233</td>\n",
       "      <td>0.6692</td>\n",
       "      <td>0.7854</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.6030</td>\n",
       "      <td>1.2917</td>\n",
       "      <td>0.8672</td>\n",
       "      <td>0.9594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 4</th>\n",
       "      <td>1.9146</td>\n",
       "      <td>0.9006</td>\n",
       "      <td>0.9228</td>\n",
       "      <td>0.7593</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>1.5139</td>\n",
       "      <td>1.1342</td>\n",
       "      <td>1.1965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 5</th>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.6677</td>\n",
       "      <td>0.6529</td>\n",
       "      <td>0.6744</td>\n",
       "      <td>0.6648</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>0.7007</td>\n",
       "      <td>0.6688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 6</th>\n",
       "      <td>1.0774</td>\n",
       "      <td>0.6292</td>\n",
       "      <td>0.7017</td>\n",
       "      <td>0.6417</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.1102</td>\n",
       "      <td>0.7542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 7</th>\n",
       "      <td>0.9124</td>\n",
       "      <td>0.6270</td>\n",
       "      <td>0.6018</td>\n",
       "      <td>0.5997</td>\n",
       "      <td>0.6707</td>\n",
       "      <td>0.7960</td>\n",
       "      <td>0.6973</td>\n",
       "      <td>0.0842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Factor 0  Factor 1  Factor 2  Factor 3  Factor 4  Factor 5  \\\n",
       "Base Factor 0    0.0816    0.6774    0.6529    0.7140    0.6940    0.6615   \n",
       "Base Factor 1    1.2915    0.1569    0.6800    0.5875    0.6581    1.0525   \n",
       "Base Factor 2    1.1962    0.6670    0.1726    0.6418    0.6491    1.0343   \n",
       "Base Factor 3    1.6233    0.6692    0.7854    0.1804    0.6030    1.2917   \n",
       "Base Factor 4    1.9146    0.9006    0.9228    0.7593    0.2583    1.5139   \n",
       "Base Factor 5    0.8440    0.6677    0.6529    0.6744    0.6648    0.1562   \n",
       "Base Factor 6    1.0774    0.6292    0.7017    0.6417    0.6875    0.9193   \n",
       "Base Factor 7    0.9124    0.6270    0.6018    0.5997    0.6707    0.7960   \n",
       "\n",
       "               Factor 6  Factor 7  \n",
       "Base Factor 0    0.6616    0.6273  \n",
       "Base Factor 1    0.7259    0.7938  \n",
       "Base Factor 2    0.7871    0.7483  \n",
       "Base Factor 3    0.8672    0.9594  \n",
       "Base Factor 4    1.1342    1.1965  \n",
       "Base Factor 5    0.7007    0.6688  \n",
       "Base Factor 6    0.1102    0.7542  \n",
       "Base Factor 7    0.6973    0.0842  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raae_df = pd.DataFrame(data=np.array(batch_results0[\"perturb results\"][0][\"all_raae\"]), columns=df_columns, index=df_index)\n",
    "print(\"RAAE Matrix\")\n",
    "raae_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9e7be23-a1da-46e9-9503-40974a468494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMC Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Factor 0</th>\n",
       "      <th>Factor 1</th>\n",
       "      <th>Factor 2</th>\n",
       "      <th>Factor 3</th>\n",
       "      <th>Factor 4</th>\n",
       "      <th>Factor 5</th>\n",
       "      <th>Factor 6</th>\n",
       "      <th>Factor 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Base Factor 0</th>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 1</th>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.9505</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.0984</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 2</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.9874</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 3</th>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.9065</td>\n",
       "      <td>0.1029</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 4</th>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>0.9656</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 5</th>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.9385</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 6</th>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.9354</td>\n",
       "      <td>0.0683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Factor 7</th>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0477</td>\n",
       "      <td>0.0546</td>\n",
       "      <td>0.9185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Factor 0  Factor 1  Factor 2  Factor 3  Factor 4  Factor 5  \\\n",
       "Base Factor 0    0.9693    0.0551    0.0046    0.0024    0.0464    0.0163   \n",
       "Base Factor 1    0.0484    0.9505    0.0096    0.0209    0.0984    0.0146   \n",
       "Base Factor 2    0.0008    0.0706    0.9874    0.0052    0.0001    0.0020   \n",
       "Base Factor 3    0.0159    0.0637    0.0500    0.9065    0.1029    0.0048   \n",
       "Base Factor 4    0.0296    0.0650    0.0002    0.1204    0.9656    0.0163   \n",
       "Base Factor 5    0.0133    0.0255    0.0005    0.0075    0.0040    0.9385   \n",
       "Base Factor 6    0.0036    0.0020    0.0425    0.0500    0.0057    0.0060   \n",
       "Base Factor 7    0.0011    0.0206    0.0303    0.0582    0.0040    0.0477   \n",
       "\n",
       "               Factor 6  Factor 7  \n",
       "Base Factor 0    0.0086    0.0168  \n",
       "Base Factor 1    0.0212    0.0125  \n",
       "Base Factor 2    0.0051    0.0262  \n",
       "Base Factor 3    0.0548    0.1290  \n",
       "Base Factor 4    0.0009    0.0026  \n",
       "Base Factor 5    0.0051    0.0558  \n",
       "Base Factor 6    0.9354    0.0683  \n",
       "Base Factor 7    0.0546    0.9185  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emc_df = pd.DataFrame(data=np.array(batch_results0[\"perturb results\"][1][\"all_emc\"]), columns=df_columns, index=df_index)\n",
    "print(\"EMC Matrix\")\n",
    "emc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd9da98a-4f4d-464b-9add-71304af52b5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9464647056057595"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_emc = np.mean(np.diagonal(emc_df.values))\n",
    "mean_emc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12652c5a-b8e6-43f5-8c44-199493ffef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import min_weight_full_bipartite_matching\n",
    "\n",
    "# Optimized Factor Search Algorithm\n",
    "# Step 1: check indices of max/min values (corr,emc/raae) by column. If all are unique this is the optimal mapping.\n",
    "# Step 2: perform a min weight full bipartite matching, where each column index is mapped to a row index to maximize or minimize the sum of matching.\n",
    "\n",
    "def optimal_mapping_algorithm(batch_results, mapping_type: str = \"raae\"):\n",
    "    n_factors = batch_results[\"k\"]\n",
    "    batch_mapping = {}\n",
    "    batch_values = {}\n",
    "    for i, p_model in batch_results[\"perturb results\"].items():\n",
    "        model_mapping = None\n",
    "        mapping_values = [-1 for i in range(n_factors)]\n",
    "        mapping_matrix = None\n",
    "        if mapping_type == \"raae\":\n",
    "            optimal_indices = np.array(p_model[\"all_raae\"]).argmin(axis=0)\n",
    "            mapping_matrix = np.array(p_model[\"all_raae\"])\n",
    "            maximize = False\n",
    "        elif mapping_type == \"emc\":\n",
    "            optimal_indices = np.array(p_model[\"all_emc\"]).argmax(axis=0)\n",
    "            mapping_matrix = np.array(p_model[\"all_emc\"])\n",
    "            maximize = True\n",
    "        else:\n",
    "            optimal_indices = np.array(p_model[\"all_corr\"]).argmax(axis=0)\n",
    "            mapping_matrix = np.array(p_model[\"all_corr\"])\n",
    "            maximize = True\n",
    "\n",
    "        # Step 1, all optimal value indices are unique and no other values need to be checked.\n",
    "        if (np.unique(optimal_indices, return_counts=True)[1].max() == 1):\n",
    "            model_mapping = optimal_indices\n",
    "        else:\n",
    "            m_bi_matrix = csr_matrix(mapping_matrix)\n",
    "            model_mapping = list(min_weight_full_bipartite_matching(m_bi_matrix, maximize=maximize))\n",
    "        optimal_index_tuples = list(zip(list(range(n_factors)), model_mapping))\n",
    "        for j, oi in enumerate(optimal_index_tuples):\n",
    "            ele_values = mapping_matrix[oi]\n",
    "            mapping_values[j] = np.round(ele_values, 4)\n",
    "        \n",
    "        batch_mapping[i] = optimal_indices\n",
    "        batch_values[i] = mapping_values\n",
    "        \n",
    "    return batch_mapping, batch_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35e1658b-068c-4c97-8525-108e5b9dec45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int64),\n",
       "  1: array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int64),\n",
       "  2: array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int64),\n",
       "  3: array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int64),\n",
       "  4: array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int64),\n",
       "  5: array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int64),\n",
       "  6: array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int64),\n",
       "  7: array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int64),\n",
       "  8: array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int64),\n",
       "  9: array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int64)},\n",
       " {0: [0.9592, 0.9578, 0.969, 0.9089, 0.9632, 0.9722, 0.9821, 0.9792],\n",
       "  1: [0.9693, 0.9505, 0.9874, 0.9065, 0.9656, 0.9385, 0.9354, 0.9185],\n",
       "  2: [0.9812, 0.9597, 0.8922, 0.8714, 0.977, 0.944, 0.9547, 0.9626],\n",
       "  3: [0.9574, 0.9547, 0.946, 0.8236, 0.8584, 0.9203, 0.7744, 0.9364],\n",
       "  4: [0.9562, 0.9782, 0.9684, 0.8587, 0.6789, 0.9031, 0.9855, 0.9783],\n",
       "  5: [0.9723, 0.9619, 0.9571, 0.9264, 0.9557, 0.9526, 0.9776, 0.9757],\n",
       "  6: [0.9182, 0.9669, 0.9423, 0.7105, 0.9234, 0.9142, 0.9294, 0.9467],\n",
       "  7: [0.9583, 0.9579, 0.9275, 0.866, 0.8958, 0.9615, 0.7233, 0.9229],\n",
       "  8: [0.7985, 0.9635, 0.9214, 0.9149, 0.8967, 0.946, 0.9025, 0.9692],\n",
       "  9: [0.9325, 0.989, 0.94, 0.8702, 0.9548, 0.9565, 0.7861, 0.9512]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_results = optimal_mapping_algorithm(batch_results=batch_results0, mapping_type=\"emc\")\n",
    "mapping_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "457f78ec-bbd6-40de-b90a-c69d2b587570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_map = np.array(mapping_results[1][0]) > 0.95\n",
    "threshold_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19314935-f271-47ec-a5ff-a4eeab7fa743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34a00b0f-983a-455f-9e9f-d658ca65868d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QTrue - Base: 12061.8693, Perturb Mean: 2290.1585, Perturb STD: 129.1735, Perturb Min: 2104.1635, Perturb Max: 2505.7105\n"
     ]
    }
   ],
   "source": [
    "base_H = batch_results0[\"base model\"].H\n",
    "base_H = (base_H / np.sum(base_H, axis=0))\n",
    "threshold = 0.95\n",
    "\n",
    "p_Hs = []\n",
    "p_Qs = []\n",
    "for p, p_results in batch_results0[\"perturb results\"].items():\n",
    "    p_model = p_results[\"model\"]\n",
    "    p_H = (p_model.H / np.sum(p_model.H, axis=0))\n",
    "    _p_H = []\n",
    "    p_mapping = mapping_results[0][p]\n",
    "    p_map_metric = np.array(mapping_results[1][p]) > threshold\n",
    "    for i in range(p_model.factors):\n",
    "        if p_map_metric[i]:\n",
    "            _p_H.append(p_H[p_mapping[i]])\n",
    "        else:\n",
    "            _p_H.append(base_H[p_mapping[i]])\n",
    "    _p_H = np.array(_p_H)\n",
    "    p_Hs.append(p_H)\n",
    "    p_Qs.append(p_model.Qtrue)\n",
    "perturb_H = np.dstack(p_Hs)\n",
    "mean_perturb_H = np.mean(perturb_H, axis=2)\n",
    "std_perturb_H = np.std(perturb_H, axis=2)\n",
    "min_perturb_H = np.min(perturb_H, axis=2)\n",
    "max_perturb_H = np.max(perturb_H, axis=2)\n",
    "\n",
    "feature_labels = [f\"Feature {i+1}\" for i in range(base_H.shape[1])]\n",
    "print(f\"QTrue - Base: {np.round(batch_results0[\"base model\"].Qtrue,4)}, Perturb Mean: {np.round(np.mean(p_Qs),4)}, Perturb STD: {np.round(np.std(p_Qs),4)}, Perturb Min: {np.round(np.min(p_Qs),4)}, Perturb Max: {np.round(np.max(p_Qs),4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef04f921-bd27-493d-8b73-712e67081afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12061.86926399749"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_results0[\"base model\"].Qtrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ec70aa6-2997-4cad-893c-504c7bacc86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base</th>\n",
       "      <th>Mean Perturb</th>\n",
       "      <th>% diff</th>\n",
       "      <th>STD Perturb</th>\n",
       "      <th>Min Perturb</th>\n",
       "      <th>Max Perturb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Feature 1</th>\n",
       "      <td>0.1555</td>\n",
       "      <td>0.1547</td>\n",
       "      <td>-0.5557</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0827</td>\n",
       "      <td>0.2464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 2</th>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>25.1585</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 3</th>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>-9.6511</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 4</th>\n",
       "      <td>0.4084</td>\n",
       "      <td>0.3936</td>\n",
       "      <td>-3.6823</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.3436</td>\n",
       "      <td>0.4516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 5</th>\n",
       "      <td>0.2568</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>1.2598</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.2134</td>\n",
       "      <td>0.3409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 6</th>\n",
       "      <td>0.4090</td>\n",
       "      <td>0.4002</td>\n",
       "      <td>-2.1716</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.3644</td>\n",
       "      <td>0.4573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 7</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 8</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 9</th>\n",
       "      <td>0.3007</td>\n",
       "      <td>0.3021</td>\n",
       "      <td>0.4614</td>\n",
       "      <td>0.0469</td>\n",
       "      <td>0.2068</td>\n",
       "      <td>0.3894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 10</th>\n",
       "      <td>0.2439</td>\n",
       "      <td>0.2319</td>\n",
       "      <td>-5.0589</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.2857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 11</th>\n",
       "      <td>0.5519</td>\n",
       "      <td>0.5379</td>\n",
       "      <td>-2.5722</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>0.5693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 12</th>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>-11.0285</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 13</th>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>-39.2805</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 14</th>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>9.6762</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 15</th>\n",
       "      <td>0.2573</td>\n",
       "      <td>0.2795</td>\n",
       "      <td>8.2678</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.2131</td>\n",
       "      <td>0.3540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 16</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 17</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 18</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 19</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>200.0000</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 20</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 21</th>\n",
       "      <td>0.4795</td>\n",
       "      <td>0.4536</td>\n",
       "      <td>-5.5452</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>0.4031</td>\n",
       "      <td>0.4989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 22</th>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>93.9503</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 23</th>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>-3.5749</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 24</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Base  Mean Perturb   % diff  STD Perturb  Min Perturb  \\\n",
       "Feature 1  0.1555        0.1547  -0.5557       0.0463       0.0827   \n",
       "Feature 2  0.0368        0.0474  25.1585       0.0301       0.0000   \n",
       "Feature 3  0.0302        0.0274  -9.6511       0.0352       0.0000   \n",
       "Feature 4  0.4084        0.3936  -3.6823       0.0310       0.3436   \n",
       "Feature 5  0.2568        0.2600   1.2598       0.0362       0.2134   \n",
       "Feature 6  0.4090        0.4002  -2.1716       0.0291       0.3644   \n",
       "Feature 7  0.0000        0.0000   0.0000       0.0000       0.0000   \n",
       "Feature 8  0.0000        0.0000   0.0000       0.0000       0.0000   \n",
       "Feature 9  0.3007        0.3021   0.4614       0.0469       0.2068   \n",
       "Feature 10 0.2439        0.2319  -5.0589       0.0435       0.1646   \n",
       "Feature 11 0.5519        0.5379  -2.5722       0.0267       0.4773   \n",
       "Feature 12 0.0490        0.0439 -11.0285       0.0138       0.0258   \n",
       "Feature 13 0.1025        0.0689 -39.2805       0.0542       0.0000   \n",
       "Feature 14 0.0096        0.0106   9.6762       0.0111       0.0000   \n",
       "Feature 15 0.2573        0.2795   8.2678       0.0390       0.2131   \n",
       "Feature 16 0.0000        0.0000   0.0000       0.0000       0.0000   \n",
       "Feature 17 0.0000        0.0000   0.0000       0.0000       0.0000   \n",
       "Feature 18 0.0000        0.0000   0.0000       0.0000       0.0000   \n",
       "Feature 19 0.0000        0.0054 200.0000       0.0109       0.0000   \n",
       "Feature 20 0.0000        0.0000   0.0000       0.0000       0.0000   \n",
       "Feature 21 0.4795        0.4536  -5.5452       0.0301       0.4031   \n",
       "Feature 22 0.0161        0.0445  93.9503       0.0488       0.0000   \n",
       "Feature 23 0.0120        0.0115  -3.5749       0.0129       0.0000   \n",
       "Feature 24 0.0000        0.0000   0.0000       0.0000       0.0000   \n",
       "\n",
       "            Max Perturb  \n",
       "Feature 1        0.2464  \n",
       "Feature 2        0.0824  \n",
       "Feature 3        0.0943  \n",
       "Feature 4        0.4516  \n",
       "Feature 5        0.3409  \n",
       "Feature 6        0.4573  \n",
       "Feature 7        0.0000  \n",
       "Feature 8        0.0000  \n",
       "Feature 9        0.3894  \n",
       "Feature 10       0.2857  \n",
       "Feature 11       0.5693  \n",
       "Feature 12       0.0722  \n",
       "Feature 13       0.1655  \n",
       "Feature 14       0.0292  \n",
       "Feature 15       0.3540  \n",
       "Feature 16       0.0000  \n",
       "Feature 17       0.0000  \n",
       "Feature 18       0.0000  \n",
       "Feature 19       0.0294  \n",
       "Feature 20       0.0000  \n",
       "Feature 21       0.4989  \n",
       "Feature 22       0.1708  \n",
       "Feature 23       0.0318  \n",
       "Feature 24       0.0000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_i = 1\n",
    "f1_dict = {\n",
    "    \"Base\": base_H[factor_i],\n",
    "    \"Mean Perturb\": mean_perturb_H[factor_i],\n",
    "    \"% diff\": np.round(100*(mean_perturb_H[factor_i] - base_H[factor_i])/((mean_perturb_H[factor_i] + base_H[factor_i])/2) , 4),\n",
    "    \"STD Perturb\": std_perturb_H[factor_i],\n",
    "    \"Min Perturb\": min_perturb_H[factor_i],\n",
    "    \"Max Perturb\": max_perturb_H[factor_i],\n",
    "}\n",
    "f1_dict[\"% diff\"][f1_dict[\"Mean Perturb\"] < 1e-6] = 0.0 \n",
    "\n",
    "f1_df = pd.DataFrame(f1_dict, index=feature_labels).round(10)\n",
    "f1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fedfebe-0f13-4bcb-915d-695e5491e6ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'base_wh'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbatch_results0\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase_wh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mKeyError\u001b[0m: 'base_wh'"
     ]
    }
   ],
   "source": [
    "batch_results0[\"base_wh\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d4bebd-11b8-4df4-8144-29165852462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_i = 0\n",
    "factor_p0_fig = make_subplots()\n",
    "for i in range(len(feature_labels)):\n",
    "    f_feature_i = perturb_H[factor_i,i]\n",
    "    factor_p0_fig.add_trace(go.Box(y=f_feature_i, name=feature_labels[i]))\n",
    "factor_p0_fig.add_trace(go.Scatter(x=feature_labels, y=base_H[factor_i], name=\"Base\", mode=\"markers\", marker_color=\"black\"))\n",
    "factor_p0_fig.update_layout(title=f\"Perturbed Factor {factor_i} Profile Results\", width=1200, height=800, hovermode='x unified')\n",
    "factor_p0_fig.update_yaxes(title_text=\"Normalized Profile\")\n",
    "factor_p0_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d99860-27eb-4e50-a815-40eda41d0048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32d64795-f1bb-4668-ab4b-ae81777d8529",
   "metadata": {},
   "source": [
    "## Batch Perturbation Instance\n",
    "\n",
    "Run multiple single perturbation instances, creating a collection of base models and their corresponding perturbed models. Create a dictionary of factor profiles, linking them to a model and factor profile by correlation mapping (above a specified threshold).\n",
    "\n",
    "Aggregated results will include:\n",
    "1. A list of factor profiles and their % occurrence across all base models\n",
    "2. The base models which include the highest % occuring factor profiles\n",
    "3. The factor profile ranges across the perturbed models sharing those factor profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4001717d-883b-47c9-9ec3-baf3a53c98d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch_perturbation(factors, v, u, random_seed, v_collection=None, batches=10, perturb_p=0.5, perturb_v=0.05, models=100, max_iter=20000, converge_n=20, converge_delta=0.01, threshold=0.9):\n",
    "    batch_collections = []\n",
    "    for b in trange(batches, desc='Running Perturbation Instances'):\n",
    "        b_seed = rng.integers(low=1, high=1e10)\n",
    "        batch_results = run_perturbation(factors=factors, v=v, u=u, random_seed=b_seed, v_collection=v_collection, perturb_p=perturb_p, perturb_v=perturb_v, models=n_models, max_iter=max_iter, converge_n=converge_n, converge_delta=converge_delta, threshold=threshold, pg_leave=False)\n",
    "        batch_collections.append(batch_results)\n",
    "    return batch_collections\n",
    "\n",
    "def check_factor_catalog_V(factor_V, factor_catalog):\n",
    "    best_r2 = 0.0\n",
    "    mapped_k = -1\n",
    "    for factor_i, factor_details in factor_catalog.items():\n",
    "        vk_r2_list = []\n",
    "        for f_Vk in factor_details[\"Vk\"]:\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                vk_r2 = FactorCompare.calculate_correlation(f_Vk.flatten(), factor_V.flatten())\n",
    "            vk_r2_list.append(vk_r2)\n",
    "        vk_r2_mean = np.mean(vk_r2_list)\n",
    "        if vk_r2_mean > best_r2:\n",
    "            best_r2 = vk_r2_mean\n",
    "            mapped_k = factor_details[\"idx\"]\n",
    "    return best_r2, mapped_k\n",
    "\n",
    "def map_batch_factors_V(batch_results, threshold=0.95):\n",
    "    base_models = [bm[\"base_model\"] for bm in batch_results]\n",
    "    base_wh = [bm[\"base_wh\"] for bm in batch_results]\n",
    "    factors = base_models[0].factors\n",
    "    factor_n = 0\n",
    "    factor_catalog = {}\n",
    "    for batch_i, batch_result in enumerate(base_models):\n",
    "        H_i = batch_result.H\n",
    "        norm_Hi = (H_i / np.sum(H_i, axis=0))\n",
    "        \n",
    "        wh_i = base_wh[batch_i]\n",
    "        for k in range(factors):\n",
    "            if batch_i == 0:\n",
    "                factor_catalog[f\"Factor {factor_n}\"] = {\"profile\": [norm_Hi[k]], \"Vk\": [wh_i[k]],  \"models\": [batch_i], \"r2\": [1.0], \"mapping\": [k], \"idx\": factor_n}\n",
    "                factor_n += 1\n",
    "            else:\n",
    "                best_r2, mapped_k = check_factor_catalog_V(wh_i[k], factor_catalog)\n",
    "                if best_r2 > threshold:\n",
    "                    factor_catalog[f\"Factor {mapped_k}\"][\"profile\"].append(norm_Hi[k])\n",
    "                    factor_catalog[f\"Factor {mapped_k}\"][\"models\"].append(batch_i)\n",
    "                    factor_catalog[f\"Factor {mapped_k}\"][\"r2\"].append(best_r2)\n",
    "                    factor_catalog[f\"Factor {mapped_k}\"][\"mapping\"].append(k)\n",
    "                    factor_catalog[f\"Factor {mapped_k}\"][\"Vk\"].append(wh_i[k])\n",
    "                else:\n",
    "                    factor_catalog[f\"Factor {factor_n}\"] = {\"profile\": [norm_Hi[k]], \"Vk\": [wh_i[k]], \"models\": [batch_i], \"r2\": [1.0], \"mapping\": [k], \"idx\": factor_n}\n",
    "                    factor_n += 1\n",
    "    return factor_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8881cd-73af-4867-b1ff-034698685b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_factors = 6\n",
    "n_batches = 20\n",
    "n_models = 5\n",
    "threshold = 0.95\n",
    "\n",
    "perturb_p = 0.5\n",
    "perturb_v = 0.05\n",
    "\n",
    "# The perturbed max percent change and percent occurrence can be defined by feature by providing a list of value, corresponding to a feature by index.\n",
    "# perturb_v = [ rng.uniform(low=0.0, high=0.1, size=None) for i in range(iV.shape[1])]\n",
    "# perturb_p = [ rng.uniform(low=0.1, high=0.5, size=None) for i in range(iV.shape[1])]\n",
    "\n",
    "batch_results = run_batch_perturbation(factors=n_factors, v=iV, u=iU, batches=n_batches, random_seed=random_seed, perturb_p=perturb_p, perturb_v=perturb_v, models=n_models, max_iter=10000, converge_n=20, converge_delta=0.01, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746cd6f-fdd4-4014-96ea-a3edc328a49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the occurrences of each factor in all the batch base models\n",
    "\n",
    "profiles_dict = map_batch_factors_V(batch_results=batch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0015e-e002-4c31-9b15-b0ee07aa9382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# factor_i = 1\n",
    "# f_name = f\"Factor {factor_i}\"\n",
    "# samples = list(range(batch_results[0][\"base_wh\"][0].shape[0]))\n",
    "# feature_j = 0\n",
    "\n",
    "# # # Feature line plot for \n",
    "# ffv_fig = make_subplots()\n",
    "# for f_i in range(len(profiles_dict[f_name][\"Vk\"])):\n",
    "#     ffv_fig.add_trace(go.Scatter(y=profiles_dict[f_name][\"Vk\"][f_i][:,feature_j], x=samples, name=f\"Model {profiles_dict[f_name][\"models\"][f_i]} - R2 {np.round(profiles_dict[f_name][\"r2\"][f_i],4)}\"))\n",
    "\n",
    "# ffv_fig.update_layout(title=f\"{f_name} - Feature {feature_j} Concentrations Across Models\", width=1200, height=800, hovermode='x unified')\n",
    "# ffv_fig.update_yaxes(title_text=\"Concentration\")\n",
    "# ffv_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610165b1-4d9a-462d-843a-e450fb00ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display factor counts, occurrences, and mean r2 value\n",
    "factor_occurrence = [round(100 * len(f[\"models\"])/n_batches, 2) for _, f in profiles_dict.items()]\n",
    "factor_count = [len(f[\"models\"]) for _, f in profiles_dict.items()]\n",
    "factor_mean_r2 = [round(np.mean(f[\"r2\"]), 4) for _, f in profiles_dict.items()]\n",
    "profiles_df = pd.DataFrame(data={\"factors\": profiles_dict.keys(), \"count\": factor_count,  \"% occurrence\": factor_occurrence, \"mean R2\": factor_mean_r2})\n",
    "profiles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140cc1e5-5fd3-4180-8ca4-5155dac94959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scores for each of the models based upon the occurrences of the profiles across all batches\n",
    "model_scores = [0 for i in range(n_batches)]\n",
    "for f_name, factor_details in profiles_dict.items():\n",
    "    f_i = int(f_name.split(\" \")[1])\n",
    "    for i in factor_details[\"models\"]:\n",
    "        model_scores[i] += factor_occurrence[f_i]\n",
    "models_ranked = np.flip(np.argsort(model_scores))\n",
    "print(f\"Model Scores by Index: {model_scores}\")\n",
    "print(f\"Models Ordered by Score: {models_ranked}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ae0f95-fcac-4196-809d-74865c38eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualte a specific factor profile range across all perturbations and models\n",
    "# For the specified factor, calculate the mean profile values from all the base models.\n",
    "# Then stack all perturbed models for that factor and generate box plot\n",
    "factor_selected = 1\n",
    "f_name = f\"Factor {factor_selected}\"\n",
    "f_details = profiles_dict[f_name]\n",
    "\n",
    "f_matrix = np.array(f_details[\"profile\"])\n",
    "f_matrix = np.dstack(f_matrix)[0]\n",
    "\n",
    "# Factor ranges from the base model profiles\n",
    "factor_base_fig = make_subplots()\n",
    "for i in range(len(feature_labels)):\n",
    "    b_feature_i = f_matrix[i]\n",
    "    factor_base_fig.add_trace(go.Box(y=b_feature_i, name=feature_labels[i]))\n",
    "\n",
    "factor_base_fig.update_layout(title=f\"Base Factor {factor_selected} Profile Results - N Models: {len(f_details[\"models\"])}\", width=1200, height=800, hovermode='x unified')\n",
    "factor_base_fig.update_yaxes(title_text=\"Normalized Profile\", range=[0, 1.0])\n",
    "factor_base_fig.show()\n",
    "\n",
    "# Factor profile ranges from the perturbed models which have a base model that mapped\n",
    "perturb_profile = []\n",
    "for i, base_i in enumerate(f_details[\"models\"]):\n",
    "    batch_result = batch_results[base_i][\"perturb_models\"]\n",
    "    mapped_factor = f_details['mapping'][i]\n",
    "    for p_model in batch_result:\n",
    "        norm_H = p_model.H / np.sum(p_model.H, axis=0)\n",
    "        perturb_profile.append(norm_H[mapped_factor])\n",
    "perturb_matrix = np.array(perturb_profile)\n",
    "perturb_matrix = np.dstack(perturb_matrix)[0]\n",
    "\n",
    "factor_p_fig = make_subplots()\n",
    "\n",
    "for i in range(len(feature_labels)):\n",
    "    b_feature_i = perturb_matrix[i]\n",
    "    factor_p_fig.add_trace(go.Box(y=b_feature_i, name=feature_labels[i])) \n",
    "factor_p_fig.add_trace(go.Scatter(x=feature_labels, y=np.mean(f_matrix, axis=1), name=\"Base Mean\", mode=\"markers\", marker_color=\"black\"))\n",
    "factor_p_fig.update_layout(title=f\"Perturbed Factor {factor_selected} Profile Results\", width=1200, height=800, hovermode='x unified')\n",
    "factor_p_fig.update_yaxes(title_text=\"Normalized Profile\", range=[0, 1.0])\n",
    "factor_p_fig.show()\n",
    "\n",
    "# Factor line plot from factor catalog\n",
    "factor_mapping_fig = make_subplots()\n",
    "for f_i in range(len(f_details[\"profile\"])):\n",
    "    factor_mapping_fig.add_trace(go.Scatter(y=f_details[\"profile\"][f_i], x=feature_labels, name=f\"Model {f_details[\"models\"][f_i]} - Factor {f_details[\"mapping\"][f_i]} - R2 {np.round(f_details[\"r2\"][f_i],4)}\"))\n",
    "\n",
    "factor_mapping_fig.update_layout(title=f\"{f_name} Mapping\", width=1200, height=800, hovermode='x unified')\n",
    "factor_mapping_fig.update_yaxes(title_text=\"Normalized Profile\", range=[0, 1.0])\n",
    "factor_mapping_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85116c-b5fb-4e28-86f8-ea91cdc1bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When running a large number of initial models use the mean values of the most frequent profiles as the initial profiles for a new SA model and see how well it performs, in terms of loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0320c8a8-8146-44a7-8a1b-cb1d58b21693",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_df_sorted = profiles_df.sort_values(by='% occurrence', ascending=False)\n",
    "profiles_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fe045f-c1d7-4b75-95e6-abab6479cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_factor_list = list(profiles_df_sorted[\"factors\"][0:5])\n",
    "optimal_factor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e05e369-221c-48a2-b221-22b81de2b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal_factor_list = ['Factor 4']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
