{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5686853f-4655-4e79-af04-fe24aac1756e",
   "metadata": {
    "id": "5686853f-4655-4e79-af04-fe24aac1756e"
   },
   "source": [
    "## NMF-PY Workflow\n",
    "\n",
    "The steps in this notebook are intended to replicate the preprocessing, base model building, and base model post-processing steps of PMF5.\n",
    "\n",
    "The error estimation functionality has not yet been implemented in the new code base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b01571c-a954-4399-a913-eeb39cfe91db",
   "metadata": {
    "id": "3b01571c-a954-4399-a913-eeb39cfe91db"
   },
   "outputs": [],
   "source": [
    "# Notebook imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "sys.path.insert(0, \"/content/nmf_py-main\")\n",
    "sys.path.insert(0, \"/content/nmf_py-main/src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbbb442-6b3d-4a6e-a843-855ede16f734",
   "metadata": {
    "id": "2cbbb442-6b3d-4a6e-a843-855ede16f734"
   },
   "source": [
    "#### Sample Dataset\n",
    "The three sample datasets from PMF5 are available for use, but a new dataset can be used in their place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d103181a-dbbe-42df-8fa7-9aa195ef20ed",
   "metadata": {
    "id": "d103181a-dbbe-42df-8fa7-9aa195ef20ed"
   },
   "outputs": [],
   "source": [
    "# Baton Rouge Dataset\n",
    "br_input_file = os.path.join(\"/content/nmf_py-main/data/Dataset-BatonRouge-con.csv\")\n",
    "br_uncertainty_file = os.path.join(\"/content/nmf_py-main/data/Dataset-BatonRouge-unc.csv\")\n",
    "br_output_path = os.path.join(\"/content/nmf_py/data-main/output/BatonRouge\")\n",
    "# Baltimore Dataset\n",
    "# b_input_file = os.path.join(\"data\", \"Dataset-Baltimore_con.txt\")\n",
    "# b_uncertainty_file = os.path.join(\"data\", \"Dataset-Baltimore_unc.txt\")\n",
    "# b_output_path = os.path.join(\"data\", \"output\", \"Baltimore\")\n",
    "# Saint Louis Dataset\n",
    "# sl_input_file = os.path.join(\"data\", \"Dataset-StLouis-con.csv\")\n",
    "# sl_uncertainty_file = os.path.join(\"data\", \"Dataset-StLouis-unc.csv\")\n",
    "# sl_output_path = os.path.join(\"data\", \"output\", \"StLouis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nfcV85xTw56x",
   "metadata": {
    "id": "nfcV85xTw56x"
   },
   "outputs": [],
   "source": [
    "# !unzip /content/nmf_py-main-20231012.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6liOt3ikAIxC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6liOt3ikAIxC",
    "outputId": "a7ecce87-001e-4f2e-cd18-46dc5a703cf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzy-c-means in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: joblib<2.0.0,>=1.2.0 in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (from fuzzy-c-means) (1.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.21.1 in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (from fuzzy-c-means) (1.24.3)\n",
      "Requirement already satisfied: pydantic<2.0.0,>=1.9.0 in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (from fuzzy-c-means) (1.10.8)\n",
      "Requirement already satisfied: tabulate<0.9.0,>=0.8.9 in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (from fuzzy-c-means) (0.8.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (from fuzzy-c-means) (4.65.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.4.0 in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (from fuzzy-c-means) (0.4.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (from pydantic<2.0.0,>=1.9.0->fuzzy-c-means) (4.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (from tqdm<5.0.0,>=4.64.1->fuzzy-c-means) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (from typer<0.5.0,>=0.4.0->fuzzy-c-means) (8.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzy-c-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770385fe-48ab-47c4-bdbb-50bab6950d05",
   "metadata": {
    "id": "770385fe-48ab-47c4-bdbb-50bab6950d05"
   },
   "source": [
    "#### Code Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e368db8a-f7f5-4b5e-b2e0-80921532d121",
   "metadata": {
    "id": "e368db8a-f7f5-4b5e-b2e0-80921532d121"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatahandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataHandler\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnmf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NMF\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_nmf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchNMF\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.data.datahandler import DataHandler\n",
    "from src.model.nmf import NMF\n",
    "from src.model.batch_nmf import BatchNMF\n",
    "from src.data.analysis import ModelAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f532c5-1e71-4966-8edf-e8f68fa0bd57",
   "metadata": {
    "id": "84f532c5-1e71-4966-8edf-e8f68fa0bd57"
   },
   "source": [
    "#### Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2281601e-af6e-43b4-80eb-317ebfaf5ede",
   "metadata": {
    "id": "2281601e-af6e-43b4-80eb-317ebfaf5ede"
   },
   "outputs": [],
   "source": [
    "index_col = \"Date\"                  # the index of the input/uncertainty datasets\n",
    "factors = 6                         # the number of factors\n",
    "method = \"ls-nmf\"                   # \"ls-nmf\", \"ws-nmf\"\n",
    "models = 20                         # the number of models to train\n",
    "init_method = \"col_means\"           # default is column means \"col_means\", \"kmeans\", \"cmeans\"\n",
    "init_norm = True                    # if init_method=kmeans or cmeans, normalize the data prior to clustering.\n",
    "seed = 42                           # random seed for initialization\n",
    "max_iterations = 20000              # the maximum number of iterations for fitting a model\n",
    "converge_delta = 0.1                # convergence criteria for the change in loss, Q\n",
    "converge_n = 10                     # convergence criteria for the number of steps where the loss changes by less than converge_delta\n",
    "verbose = True                      # adds more verbosity to the algorithm workflow on execution.\n",
    "optimized = True                    # use the Rust code if possible\n",
    "parallel = True                     # execute the model training in parallel, multiple models at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90318121-9709-4e67-baf3-8f76432f68ed",
   "metadata": {
    "id": "90318121-9709-4e67-baf3-8f76432f68ed"
   },
   "source": [
    "#### Dataset Selection\n",
    "One of the three sample datasets can be selected or a new cleaned dataset can be used. Datasets should be cleaned, containing no missing data (either dropping missing/NaNs, or interpolating the missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f90ce2-d9d3-42cd-8a30-aa5b0b73fe77",
   "metadata": {
    "id": "16f90ce2-d9d3-42cd-8a30-aa5b0b73fe77"
   },
   "outputs": [],
   "source": [
    "# Loading the Baton Rouge dataset\n",
    "input_file = br_input_file\n",
    "uncertainty_file = br_uncertainty_file\n",
    "output_path = br_output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d605314-c34a-434d-a178-81b6f6b3766d",
   "metadata": {
    "id": "1d605314-c34a-434d-a178-81b6f6b3766d"
   },
   "source": [
    "#### Load Data\n",
    "Assign the processed data and uncertainty datasets to the variables V and U. These steps will be simplified/streamlined in a future version of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c2f332-c4f1-43c6-94ec-7b22d0cbc0ab",
   "metadata": {
    "id": "e4c2f332-c4f1-43c6-94ec-7b22d0cbc0ab"
   },
   "outputs": [],
   "source": [
    "data_handler = DataHandler(\n",
    "    input_path=input_file,\n",
    "    uncertainty_path=uncertainty_file,\n",
    "    index_col=index_col\n",
    ")\n",
    "V, U = data_handler.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412787cb-62cf-4a86-9a2d-f368030e11db",
   "metadata": {
    "id": "412787cb-62cf-4a86-9a2d-f368030e11db"
   },
   "source": [
    "#### Input/Uncertainty Data Metrics and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d28851-eee3-4682-817e-00ce63e5617b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "58d28851-eee3-4682-817e-00ce63e5617b",
    "outputId": "7ec54854-80a4-4e37-c943-20b9366562a3"
   },
   "outputs": [],
   "source": [
    "# Show the input data metrics, including signal to noise ratio of the data and uncertainty\n",
    "data_handler.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac7440-7f97-4b81-a2ac-6e539f294132",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "15ac7440-7f97-4b81-a2ac-6e539f294132",
    "outputId": "53aca77e-640a-4653-cf16-ffa8abde0c49"
   },
   "outputs": [],
   "source": [
    "# Concentration / Uncertainty Scatter plot for specific feature, feature/column specified by index\n",
    "data_handler.data_uncertainty_plot(feature_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c24b313-37ca-412f-b07b-dcd00021773b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "0c24b313-37ca-412f-b07b-dcd00021773b",
    "outputId": "9c85ed60-74f4-49ff-f787-17d26faf66da"
   },
   "outputs": [],
   "source": [
    "# Species Concentration plot comparing features, features/columns specified by index\n",
    "data_handler.feature_data_plot(x_idx=0, y_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964a8c8b-3b57-487c-b7b3-c9f6ca7dad78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "964a8c8b-3b57-487c-b7b3-c9f6ca7dad78",
    "outputId": "ea9d6f8a-ccad-4fc2-f611-a32fa984ab2d"
   },
   "outputs": [],
   "source": [
    "# Species Timeseries, a single or list of features/columns specified by index\n",
    "data_handler.feature_timeseries_plot(feature_selection=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f561829-6c19-4eeb-b8d3-3f83180b9794",
   "metadata": {
    "id": "9f561829-6c19-4eeb-b8d3-3f83180b9794"
   },
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018eb975-f9dd-4e73-bf1d-8c5b696e6dca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "018eb975-f9dd-4e73-bf1d-8c5b696e6dca",
    "outputId": "83e0cfff-00f2-456b-a07f-c23e721b10ad"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Training multiple models, optional parameters are commented out.\n",
    "nmf_models = BatchNMF(V=V, U=U, factors=factors, models=models, method=method, seed=seed, max_iter=max_iterations,\n",
    "                    # init_method=init_method, init_norm=init_norm,\n",
    "                    converge_delta=converge_delta, converge_n=converge_n,\n",
    "                    parallel=parallel, optimized=False,\n",
    "                    # verbose=verbose\n",
    "                   )\n",
    "nmf_models.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa8298-bd0f-4dea-97f9-43a9971303b2",
   "metadata": {
    "id": "23fa8298-bd0f-4dea-97f9-43a9971303b2",
    "outputId": "eb41bcad-e5c8-42f8-ffcd-ec0696017468"
   },
   "outputs": [],
   "source": [
    "# Selet the model to review, by index or the best performing from the collection of models\n",
    "best_model = nmf_models.best_model\n",
    "nmf_model = nmf_models.results[best_model]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef5ff6-a181-4342-a499-860fced9b64b",
   "metadata": {
    "id": "46ef5ff6-a181-4342-a499-860fced9b64b"
   },
   "outputs": [],
   "source": [
    "# Initialize the Model Analysis module\n",
    "model_analysis = ModelAnalysis(datahandler=data_handler, model=nmf_model, selected_model=best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d2bff7-b36a-4837-95a9-1ff2bd90c0fa",
   "metadata": {
    "id": "48d2bff7-b36a-4837-95a9-1ff2bd90c0fa",
    "outputId": "74b285b2-b004-4521-a244-762c3e58ffbb"
   },
   "outputs": [],
   "source": [
    "# Residual Analysis shows the scaled residual histogram, along with metrics and distribution curves. The abs_threshold parameter specifies the condition for the returned values of the function call as those residuals which exceed the absolute value of that threshold.\n",
    "abs_threshold = 3.0\n",
    "threshold_residuals = model_analysis.plot_residual_histogram(feature_idx=0, abs_threshold=abs_threshold)\n",
    "print(f\"List of Absolute Scaled Residual Greather than: {abs_threshold}. Count: {threshold_residuals.shape[0]}\")\n",
    "threshold_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d33c4-51b4-4c1d-b01e-7b9667638e64",
   "metadata": {
    "id": "462d33c4-51b4-4c1d-b01e-7b9667638e64",
    "outputId": "ef20c3f7-bb08-40b0-c38d-e9edf4cf0b07"
   },
   "outputs": [],
   "source": [
    "# The model output statistics for the estimated V, including SE: Standard Error metrics, and 3 normal distribution tests of the residuals (KS Normal is used in PMF5)\n",
    "model_analysis.calculate_statistics()\n",
    "model_analysis.statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d23a88-47f5-4692-ba9b-07e8630d5486",
   "metadata": {
    "id": "69d23a88-47f5-4692-ba9b-07e8630d5486",
    "outputId": "2fd58e3a-55a8-4dc1-c5f4-3b01988eaaa2"
   },
   "outputs": [],
   "source": [
    "# Model feature observed vs predicted plot with regression and one-to-one lines. Feature/Column specified by index.\n",
    "model_analysis.plot_estimated_observed(feature_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a0280-d275-46d5-973e-48fa55fd51af",
   "metadata": {
    "id": "102a0280-d275-46d5-973e-48fa55fd51af",
    "outputId": "055d81da-3463-4719-9b9a-40d5d818d38c"
   },
   "outputs": [],
   "source": [
    "# Model feature timeseries analysis plot showing the observed vs predicted values of the feature, along with the residuals shown below. Feature/column specified by index.\n",
    "model_analysis.plot_estimated_timeseries(feature_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da54785-9c7f-4396-b776-f086612ace02",
   "metadata": {
    "id": "2da54785-9c7f-4396-b776-f086612ace02",
    "outputId": "9254694b-92be-49b7-e262-7813e6489d0c"
   },
   "outputs": [],
   "source": [
    "# Factor profile plot showing the factor sum of concentrations by feature (blue bars), the percentage of the feature as the red dot, and in the bottom plot the normalized contributions by date (values are resampled at a daily timestep for timeseries consistency).\n",
    "# Factor specified by index.\n",
    "model_analysis.plot_factor_profile(factor_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e332d6-75b2-4682-ba27-612dfaf26b27",
   "metadata": {
    "id": "e8e332d6-75b2-4682-ba27-612dfaf26b27",
    "outputId": "901f1411-10e5-41b4-82cb-142f3d4a99ca"
   },
   "outputs": [],
   "source": [
    "# Model factor fingerprint specifies the feature percentage of each factor.\n",
    "model_analysis.plot_factor_fingerprints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8bb85b-b48e-4031-b861-d6f6af5ad090",
   "metadata": {
    "id": "4c8bb85b-b48e-4031-b861-d6f6af5ad090",
    "outputId": "d4795411-5545-49ff-98a1-2b184dadd4fa"
   },
   "outputs": [],
   "source": [
    "# Factor G-Space plot shows the normalized contributions of one factor vs another factor. Factor specified by index.\n",
    "model_analysis.plot_g_space(factor_1=2, factor_2=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8514eed-0747-49b0-b387-ce3379213a2e",
   "metadata": {
    "id": "5afced49-c9ff-4a44-9558-e327d07d46bc",
    "outputId": "499ec5ca-8d55-4537-a069-a7b004821e1c"
   },
   "outputs": [],
   "source": [
    "# Factor contribution pie chart shows the percentage of factor contributions for the specified feature, and the corresponding normalized contribution of each factor for that feature (bottom plot). Feature specified by index.\n",
    "model_analysis.plot_factor_contributions(feature_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e479211-fc1d-46d8-a84a-13e339143c1c",
   "metadata": {
    "id": "5afced49-c9ff-4a44-9558-e327d07d46bc",
    "outputId": "499ec5ca-8d55-4537-a069-a7b004821e1c"
   },
   "outputs": [],
   "source": [
    "# New Graphic: Factor Profile Composition Radar Graph\n",
    "model_analysis.plot_factor_composition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be971709-def7-4528-85f2-b5a1dd7e8506",
   "metadata": {
    "id": "5afced49-c9ff-4a44-9558-e327d07d46bc",
    "outputId": "499ec5ca-8d55-4537-a069-a7b004821e1c"
   },
   "outputs": [],
   "source": [
    "# New Graphic: Factor Contribution Surface Plot\n",
    "factor_idx = 1\n",
    "model_analysis.plot_factor_surface(factor_idx=factor_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccba89f-ec29-4791-b221-ecfbd4f15009",
   "metadata": {
    "id": "5aa9ec8d-6aef-4803-8646-b9e0e35e3408"
   },
   "source": [
    "### Error Estimation - Displacement\n",
    "\n",
    "The displacement method for error estimation works by make slight adjustments to the factor profile values, individually, until a specific change in the loss value (dQ) is reached. There are 4 dQ values that are targetted, dQ = 4, 8, 16, 32. \n",
    "\n",
    "The target dQ value is run for both an increase and decrease in the factor profile value, a single value in the factor profile matrix at a time. The change in factor profile is found by running a modified binary search to identify the value change within a small threshold, 0.1 of the target dQ. The value search is stopped if the change in the factor profile value is less than 1e-8, in the instance that decreasing a factor profile value already near zero.\n",
    "\n",
    "Once the change in the factor profile value is found that produces the target dQ, both increasing and decreasing, the modification to the H matrix is used as an initial guess for retraining a NMF model. The W matrix is reinitialized, using the original base model seed, and the model is trained to convergence. \n",
    "\n",
    "The resulting model factor profile is checked to see if any factors swapped base upon the highest factor correlation with the base model factors. The output shows the swap %, based upon the number of retrained models where that factor was modified and the number of times a swap was detected.\n",
    "\n",
    "The factor profile plot shows the variability in the factor profile feature values that correspond to the dQ target values, default shown in the plots is for a dQ=4. The last plot show the factor feature contribution variability based upon the same changes to the H matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd3b97f-f675-4eda-8fb8-db22fbbcbfd2",
   "metadata": {
    "id": "5aa9ec8d-6aef-4803-8646-b9e0e35e3408"
   },
   "outputs": [],
   "source": [
    "# Import Error Estimation Displacement Method\n",
    "from src.error.displacement import Displacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8cb683-1176-40d8-a46b-a9be537838ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Displacement method, passing in the results of the batch nmf run and the features labels from the data handler.\n",
    "disp = Displacement(nmf=nmf_model, feature_labels=data_handler.features, model_selected=best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b61601-2b09-4066-856d-e3895a684209",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Execute the displacement model, which will test both increasing and decreasing changes to the individual values of H for all dQ targets. Results are then compiled and prepared.\n",
    "disp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492f1b9d-2309-4034-b379-264a0909605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The swap table shows the percentage of times a factor was found to be more highly correlated as a result of the change in the factor feature value. This percentage is the number of times that a specific factor swapped after a model was retrained.\n",
    "# The largest change in the dQ value is the largest difference (both from increasing and decreasing changes to the factor feature values) between a retrained model and the base model loss value.\n",
    "disp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0abf217-b12f-4a58-bb9c-e0f81a089405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results for a specific factor can be plotted, showing both the variability in the profile(%) and contribution for a given dQ value.\n",
    "factor_i = 1\n",
    "disp.plot_results(factor=factor_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12fc496-9d20-4aeb-afb7-c50968d2fb52",
   "metadata": {},
   "source": [
    "### Error Estimation - Bootstrap\n",
    "\n",
    "The bootstrap method used is the block bootstrap method for time-series data. Here the initial dataset is broken into chunks of a specified size, containing sequential samples, and randomly added to a bootstrap dataset until the bootstrap dataset is the same size as the initial dataset.\n",
    "\n",
    "The recommended block size calculation feature has not yet been implemented. \n",
    "\n",
    "The aim of the bootstrap method is to quantify the variability in the factor profiles and contributions when the order of the datasets have been shuffled, resampled. In this case the block bootstrap method is the default method, while the full bootstrap method can be used by setting the block parameter in the run function to false, i.e. bs.run(block=False). The blocks are randomly selected with replacement, allowing for the same block to be added to the bs dataset more than once. The final selected block is reduced in size until the bs dataset is exactly the same as the initial dataset. \n",
    "\n",
    "The resampling is completed a specified number of times, set by bootstrap_n. During each bootstrap run, the initial datasets are resampled (both the data and uncertainty datasets are resampled using the same indeces) and used to retrain a NMF model. The NMF model uses the resampled data and uncertainty data, the base model H matrix and the base model random seed. W is reinitialized and the model is trained to convergence. The resulting factor contributions, $V'_{bs}$ are mapped to the base model $V'_{base}$, where the correlation between all combinations of the factor contributions are checked. The mapping between the highest correlation is then noted, if the correlation is above the user specified threshold (default=0.6), and the results are shown in the summary statistics. The summary statistics also include metrics for the distribution of the bootstrap model results to compare against the base model results, these are shown as tables for each factor in the summary statistics.\n",
    "\n",
    "The results of all the bootstrap runs are compiled to provide a distribution for each factor/feature percentage and contribution, these are shown in the plotted results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505e9f0-ca12-4cca-8870-a6b430e3dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Bootstrap Error Estimation Method\n",
    "from src.error.bootstrap import Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c571d25e-e137-4929-a3c6-ebc58adc189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap input parameters\n",
    "# Some parameters are simply reassigned for clarity.\n",
    "model_selected = nmf_models.best_model              # the model selected to be the base model for the Bootstrap method, here chosen as the best performing model from the batch nmf run.\n",
    "nmf_model = nmf_models.results[model_selected]      # The selected model NMF object.\n",
    "feature_labels = data_handler.features              # The list of feature names/labels\n",
    "\n",
    "bootstrap_n = 20                                    # The number of bootstrap runs to complete\n",
    "block_size = data_handler.optimal_block             # Calculates an optimal block size from the Politis and White 2004 algorithm (used in PMF5)\n",
    "threshold = 0.6                                     # The r-correlation threshold\n",
    "seed = seed                                         # The random seed used for random selection of the bootstrap blocks.\n",
    "print(f\"Optimal BS block size: {data_handler.optimal_block}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a6275-b39c-48c4-b7a1-6906753ee453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the bootstrap object\n",
    "bs = Bootstrap(nmf=nmf_model, feature_labels=feature_labels, model_selected=model_selected, bootstrap_n=bootstrap_n, block_size=block_size, threshold=threshold, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1dd26-741f-4b30-bcd4-135e0031d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Execute the bootstrap runs with default parameters\n",
    "bs.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a056896d-532e-4d26-a203-37aa4a997b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the output summary of all the bootstrap runs.\n",
    "bs.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccb51bc-f6e0-424d-b4a3-043ff64606d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of the bootstrap runs for a specific factor, showing the variability in percentage and concentration for each feature of the specified factor.\n",
    "factor_i = 1\n",
    "bs.plot_results(factor=factor_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7feec5e-8f4e-4465-ab82-ad13f2d43b40",
   "metadata": {},
   "source": [
    "### Error Estimation - Bootstrap-Displacement\n",
    "\n",
    "The bootstrap-displacement (BS-DISP) method is a combination of the boostrap and displacement methods. An existing BS instance can be used, or a new BS instance will be created.\n",
    "\n",
    "The BS-DISP method runs a BS instance and for each model in the BS run, DISP is run for each of the features specified or all by default. The results are similar to the DISP results by are aggregated across all bootstrap runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221d4a3-3878-4c4c-863e-400a22f1e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.error.bs_disp import BSDISP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e6d6d-5509-4dfc-b4a0-19755fa46220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap input parameters (Shared with BS-DISP)\n",
    "model_selected = nmf_models.best_model              # the model selected to be the base model for the Bootstrap method, here chosen as the best performing model from the batch nmf run.\n",
    "nmf_model = nmf_models.results[model_selected]      # The selected model NMF object.\n",
    "feature_labels = data_handler.features              # The list of feature names/labels\n",
    "\n",
    "bootstrap_n = 10                                    # The number of bootstrap runs to complete\n",
    "block_size = data_handler.optimal_block             # Calculates an optimal block size from the Politis and White 2004 algorithm (used in PMF5)\n",
    "threshold = 0.6                                     # The r-correlation threshold\n",
    "seed = seed                                         # The random seed used for random selection of the bootstrap blocks.\n",
    "\n",
    "# Displacement input parameters (Shared with BS-DISP)\n",
    "threshold_dQ = 0.1\n",
    "max_search = 50\n",
    "features = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab8ffe-6563-4a3c-b1d6-a459dcf215bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BS-DISP with the BS and DISP parameters\n",
    "bsdisp = BSDISP(nmf=nmf_model, feature_labels=feature_labels, model_selected=model_selected, bootstrap_n=bootstrap_n, block_size=block_size, threshold=threshold, max_search=max_search, threshold_dQ=threshold_dQ, features=features, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2ad1d0-6c71-4427-bbf4-5f094d919983",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Execute the BS-DISP instance, which will first run BS (if required) then will run DISP for each BS model.\n",
    "# parallel = False (CPU times: total: 1h 21min 25s, Wall time: 10min 13s)\n",
    "bsdisp.run(parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c07e373-e5a2-42da-bbfb-75f00b39d1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the summary table and general metrics\n",
    "bsdisp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c3bb7-9834-4665-8173-49c09059a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the BS-DISP results, the profile and contribution boxplots for a specific factor.\n",
    "factor_i = 1\n",
    "bsdisp.plot_results(factor=factor_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b623a8-914c-4e2b-875d-330c07c67a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The overall error summary can be shown through the follow method that will take in an existing bootstrap and displacement object and plot the error estimation for a given factor.\n",
    "from src.error.error import Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2480e2-f498-4440-b1c4-74b6b1cf6a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in the previously completed bootstrap and displacement instances\n",
    "error = Error(bs=bs, disp=disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac5a915-351c-464e-892c-dff96d9cd773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the error estimation of the concentration for a specified factor.\n",
    "factor_i = 1\n",
    "error.plot_summary(factor=factor_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acb82ca-8068-4bc3-aa1f-8568eeaeed16",
   "metadata": {},
   "source": [
    "### Rotational Tools - Fpeak\n",
    "Placeholder for fpeak summary and algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400fb608-717f-4867-afc4-b98f10915057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the module\n",
    "from src.rotational.fpeak import Fpeak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625b45fd-59d0-4bc0-b399-c6a9239fa5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize the fpeak instance and set the fpeak values\n",
    "fpeak_list = [1.0, -1.0, 1.5, -1.5, 2.5, -2.5, 5.0, -5.0]\n",
    "s = 0.1       # The softness parameter, setting lowercase s sets all values of the S array to s.\n",
    "S = None      # An array of size N, that is the softness values corresponding to each nth auxiliary equation (sample in the dataset). Used when all values of S are not the same.\n",
    "\n",
    "fp = Fpeak(base_model=nmf_model, data_handler=data_handler, fpeaks=fpeak_list, s=s, S=S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a991bc40-f47d-439d-860e-97f6c0bc58fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Fpeak instance\n",
    "max_iterations = 10000\n",
    "converge_delta = 1e-4\n",
    "converge_n = 20\n",
    "\n",
    "fp.run(max_iter=max_iterations, converge_delta=converge_delta, converge_n=converge_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fe6ef5-1be2-4906-9788-f1f9d287397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the tabled results of the fpeak runs (as shown in PMF5 - Fpeak Run Summary\n",
    "fp.results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a9bd3b-14de-4781-96f8-e01551c70297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Profiles/Contributions of a specific Fpeak value and factor\n",
    "factor_idx = 1\n",
    "fpeak = 1.0\n",
    "\n",
    "fp.plot_profile_contributions(factor_idx=factor_idx, fpeak=fpeak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0258f37c-ad07-4859-8e77-f420653bcede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Factor profiles/fingerprints \n",
    "fpeak = 1.0\n",
    "\n",
    "fp.plot_factor_fingerprints(fpeak=fpeak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac6a84d-6904-48e4-a2c7-0de1c6535998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Factor G-Space graph\n",
    "fpeak = 1.0\n",
    "factor_idx1 = 1\n",
    "factor_idx2 = 2\n",
    "show_base = True\n",
    "show_delta = True\n",
    "\n",
    "fp.plot_g_space(fpeak=fpeak, factor_idx1=factor_idx1, factor_idx2=factor_idx2, show_base=show_base, show_delta=show_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24dbf13-9dcd-4dae-86ef-6fefd9b2e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the factor contributions\n",
    "fpeak = 1.0\n",
    "feature_idx = 2\n",
    "threshold = 0.06\n",
    "\n",
    "fp.plot_factor_contributions(fpeak=fpeak, feature_idx=feature_idx, threshold=threshold)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
