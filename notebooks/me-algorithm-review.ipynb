{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4abb0f2-d0cc-4ef8-b775-315cb746bad6",
   "metadata": {},
   "source": [
    "## Multilinear Engine Algorithm Review\n",
    "\n",
    "#### Summary\n",
    "The details of this algorithm have been obtained from the publication *The Multilinear Engine: A Table-Driven, Least Squares Program for Solving Multilinear Problems, including the n-Way Parallel Factor Analysis Model*, url: https://www.jstor.org/stable/1390831.\n",
    "\n",
    "#### The Pseudocode Algorithm\n",
    "The ME1 algorithm as described in section 7.1 of the publication.\n",
    "\n",
    "1. Input control information, structure table, and data. Initialize.\n",
    "    1. Reset the coefficients for inverse preconditioning of constrained variables:   $c_n = 1.0$.\n",
    "2. Initialize a sequence of CG steps.\n",
    "    1. Compute the weights   $w_m$.\n",
    "    2. Compute the Jacobian. Convert the Jacobian table into the Jacobian matrix for computing the preconditioning coefficients   $p_n = \\frac{1}{\\sum_{m}w_{m}j_{mn}^2}$.\n",
    "    3. Set   $\\rho = 0$\n",
    "3. Perform one CG step.The initial solution consists of   $f_n$.\n",
    "    1. Compute SE factors   $f_n$ (E9.4).\n",
    "    2. Compute the current fit $y_m$ (E2.1) and the initial object function: $ Q^{(1)} = \\sum_{m=1}^{M}w_m(x_m - y_m)^2 $\n",
    "    3. Compute the components of the Jacobian: $J^{(1)}$, $J^{(2)}$, and $J^{(3)}$ (E4.3, E9.5).\n",
    "    4. Compute the gradient $g = J^TW(x - y)$ (E9.7).\n",
    "    5. Compute the transformed gradient **z** by multiplying gradient components with preconditioning coefficients: $z_n = c_{n}p_{n}g_{n}$.\n",
    "    6. If $\\rho = 0$ (if this is the first step of the sequence), set $\\beta = 0$, $\\rho = g^Tz$, else set $\\beta = \\frac{g^Tz}{\\rho}$, $\\rho = g^{T}z$.\n",
    "    7. Update the accumulated step direction:   $t = \\beta{t} + z$\n",
    "    8. Compute   $\\tau = t^{T}J^{T}WJt$,   $\\omega = t^{T}J^{T}W(x - y)$. (E9.7)\n",
    "    9. Compute the initial approximation for the step length, $\\alpha = \\frac{\\omega}{\\tau}$\n",
    "    10. Compute $Q^{(2)} = Q(max(f + \\alpha{t}, 1))$ (E9.4, E2.1).\n",
    "    11. If $Q^{(2)} < Q^{(1)}$, compute nonlinearity-corrected step length as $\\alpha = \\frac{\\alpha}{(2 - (Q^{(1)} - Q^{(2)})\\frac{\\tau}{\\omega^2})}$\n",
    "    12. else repeatedly try decreasing $\\alpha$, computing $Q^{(2)} = Q(max(f = \\alpha{t}, 1))$, until $Q^{(2)} < Q^{(1)}$, go to Step 2,\n",
    "    13. If it was impossible to satisfy $Q^{(2)} < Q^{(1)}$, go to Step 2.\n",
    "    14. else accept the new solution, set $f = max(f + \\alpha{t}, 1)$.\n",
    "4. Update inverse preconditioning. Denote indexes $n$ of *nonviolating* ($f_n > I_n$) constrained factor elements by $u$, and indexes of violating ($f_n = I_n$) constrained factor elements of $v$.\n",
    "    1. Increase $c_u$, constrained by $c_u \\le 1$.\n",
    "    2. Decrease $c_v$, constrained by $c_v \\ge \\epsilon$.\n",
    "    3. Decrease $t_v$, constrained by $t_v \\ge \\epsilon$.\n",
    "5. Write monitoring output, test for convergence.\n",
    "    1. Output to screen and to log file $Q^{(2)}$ and $\\rho$, that is, the goodness-of-fit and the squared length of the preconditioned gradient.\n",
    "    2. If $|Q^{(1)} - Q^{(2)}| < e$ ($e$ and $k$ are user-specified parameters), and if this condition has been valid in $k$ consecutive steps, assume convergence and go to the end, Step 7.\n",
    "    3. If the maximum iteration count is exceeded, go to the end, Step 7.\n",
    "6. Test for continuing this CG sequence.\n",
    "    1. If convergence is slowing down, and/or the user-specified restart limits allow it, go back to initialiing anothe rCG sequence, Step 2.\n",
    "    2. Otherwise go back to performing the next CG step in the current sequence, Step 3.\n",
    "7. The $f_n$ are the solution. Write the results. If the user has requested so, compute and write the approximate Hessian matrix $J^{T}WJ$, the exact Hessian (E8.1), or the weighted Jacobian sparse matrix $W^\\frac{1}{2}J$ (for computing these matrices, first convert the Jacobian table into the Jacobian matrix. End the run.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e47ca87-bb76-4d28-a4d1-1e4b314b8486",
   "metadata": {},
   "source": [
    "### Variables and Loss Function\n",
    "\n",
    "#### Variables\n",
    "These variables are defined in section 2.\n",
    "\n",
    "$x$: The input data which is of size $m$ features and $n$ samples.<br/>\n",
    "$m$: The index $m$ enumerates the equations that embody the model to be Solved.<br/>\n",
    "$x_m$: The data to be fitted, corresponding to a vector containing elements of $x$ which would be denoted as $x_{ijk}$.<br/>\n",
    "$y_m$: The fitted values, defined by the factor elements.<br/>\n",
    "$K_m$: The number of product terms in each equation.<br/>\n",
    "$k$: The index $k$ enumerates the products that are added together in order that their sum be an approximation of $x_m$.<br/>\n",
    "$f_n$: The vector $f$, consists of values $f_n(n=1, ..., N)$, is the collection of all factor elements of the model.<br/>\n",
    "$T_{mk}$: The index sets $T_{mk}$ defines one product in one equation.<br/>\n",
    "$\\sigma_m$: The uncertainties $\\sigma_m$ are used to generate the weights $w_m$.<br/>\n",
    "\n",
    "#### Loss Function\n",
    "As defined in section 2.<br/><br/>\n",
    "$ Q(x,f) = \\sum_{m=1}^{M}{w_m}{e_m^2} = \\sum_{m=1}^{M}{w_m}(x_m - y_m)^2$ (2.5)<br/><br/>\n",
    "$ \\hat{f} = arg min_f \\sum_{m=1}^{M}w_{m}e_m^2 = arg min_f \\sum_{m=1}^{M}(\\frac{e_m}{\\sigma_m})^2 $ (2.7)<br/><br/>\n",
    "$ \\hat{f} = arg min_f \\sum_{m=1}^{M}(\\frac{x_m - \\sum_{k=1}^{K_m}\\prod_{n\\in{T_{mk}}}f_n}{\\sigma_m})^2$ (2.8)<br/><br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58856b9c-a84f-4f09-84ad-8b431bf7a450",
   "metadata": {},
   "source": [
    "### Detailed Algorithm\n",
    "\n",
    "Taking the pseudo algorithm stated above but including the details necessary for implementation and variable assignment.\n",
    "\n",
    "#### Terminology\n",
    "\n",
    "*free factor element*: is used for the unknowns, the profile factors (H) and factor contributions (W).<br/>\n",
    "*constrained*: indicates such *free factor elements* which are required to be non-negative (H).<br/>\n",
    "*subexpression*: (SE) variables are defined in terms of the fixed and unknown elements.<br/>\n",
    "\n",
    "#### Detailed Variables\n",
    "\n",
    "Defining all variables that are specified in the pseudocode.<br/>\n",
    "$X$: Input dataset of size $m$ features by $n$ samples.<br/>\n",
    "$U$: Uncertainty dataset of size $m$ features by $n$ samples.<br/>\n",
    "$w$: Weights, which are initialially defined from $U$ and feature categories. $w_m = \\frac{1}{\\sqrt{U_m}}$<br/>\n",
    "$W$: Diagonal matrix consisting of all weights $w_m$, $m = 1, ..., M$.<br/>\n",
    "$y$: Fitted values which are the matrix product of $WH$.<br/>\n",
    "$n$: The number of samples (rows).<br/>\n",
    "$m$: The number of features (columns).<br/>\n",
    "$h$: The number of factors.<br/>\n",
    "\n",
    "$f_n$: Individual components of the loss function. Unsummed equivalent of WH.<br/>\n",
    "$f_h$: Equivalent of WH, calculated from: $f_n = \\sum_{k=1}^{S_h}\\prod_{n \\in S_{hk}}f_{n} (h = N + 1, ..., N + N^{SE})$.<br/>\n",
    "$J$: The Jacobian matrix, which is compose of three elements $J^{(1)}$, $J^{(2)}$, and $J^{(3)}$. The Jacobian is calculated from it's components defined $J = \\begin{bmatrix}J^{(1)}&J^{(2)}\\end{bmatrix} \\begin{bmatrix}I\\\\J^{(3)}\\end{bmatrix} $<br/>\n",
    "$J^{(1)}$: Component of the Jacobian matrix which consists of the partial derivatives of $y_m$ with respect to the free factor elements while keeping the SE factor elements constant.<br/>\n",
    "$J^{(2)}$: Component of the Jacobian matrix which consists of the partial derivatives of $y_m$ with respect to the SE factor elements.<br/>\n",
    "$J^{(3)}$: Component of the Jacobian matrix which consists of the partial derivatives $\\frac{\\partial{f_h}}{\\partial{f_n}} (h = N+1, ...,  N+ N^{SE}, n = 1, ..., N)$.<br/>\n",
    "$I$: Vector which contains the lower limits for factor elements, for non-negatively constrained factor elements $l_n = 0$ and for unconstrained factor elements, $l_n = -\\infty$.<br/>\n",
    "$\\epsilon$: Denotes a small constant, such as $10^{-12}$.<br/>\n",
    "\n",
    "$c$: Coefficients for inverse preconditioning of constrained variables.<br/>\n",
    "$g$: The computed gradient.<br/>\n",
    "$p$: The preconditioning coefficients.<br/>\n",
    "$z$: The transformed gradient $g$ which is the multiplicative product of the inverse preconditioning coefficient, preconditioning coefficient, and the gradient.<br/>\n",
    "$\\rho$: A componet in the calculation of the step direction.<br/> \n",
    "$\\beta$: A componet in the calculation of the step direction.<br/>\n",
    "$t$: The step direction.<br/>\n",
    "$\\alpha_k$: The step length.<br/>\n",
    "$\\tau$: A component in the calculation of the step length.<br/>\n",
    "$\\omega$: A component in the calculation of the step length.<br/>\n",
    "$e$: Convergence change threshold.<br/>\n",
    "$k$: Convergence change step. When the change in $Q$ over $k$ iterations is less than $e$ the solution is considered converged.<br/>\n",
    "\n",
    "#### Pseudocode\n",
    "\n",
    "1. Primary Initialization.\n",
    "    1. Set $c_n = 1.0$\n",
    "    2. Input dataset $X$, uncertainty $U$, initialize $W$ and $H$ matrices.\n",
    "2. CG Step Initialization.\n",
    "    1. Compute the weights $w_m$.\n",
    "    2. Compute the Jacobian: $j_{mn} = \\frac{\\partial{y_m}}{\\partial{f_n}} = \\sum_{k|n\\in T_{mk}} \\prod_{l\\in T_{mk}n}f_l$. This can be defined as the change in the WH over the change in the weighted/uncertainty squared residuals. The preconditioning coefficients are calculated using the Jacobian: $p_n = \\frac{1}{\\sum_{m}w_{m}j_{mn}^{2}}$\n",
    "    3. Set $\\rho = 0$.\n",
    "3. Perform one CG step.\n",
    "    1. Compute SE factors $f_h = \\sum_{k=1}^{S_h}\\prod_{n \\in S_{nk}}f_n$\n",
    "    2. Compute current fit $y_m$ and the initial object function: $ Q^{(1)} = \\sum_{m=1}^{M}w_m(x_m - y_m)^2 $\n",
    "    3. <span style=\"color:red\">Compute components of the Jacobian: $j_{mn} = \\frac{\\partial{y_m}}{\\partial{f_n}} = \\sum_{k|n\\in T_{mk}} \\prod_{l\\in T_{mk}n}f_l$</span>\n",
    "    4. Compute the gradient:  $g = J^TW(x - y) = J^{(1)T}W(x - y) + J^{(3)T}(J^{(2)T}W(x - y))$ using the components of the Jacobian.\n",
    "    5. Compute the transformed gradient $z_n = c_{n}p_{n}g_{n}$.\n",
    "    6. If $\\rho = 0$, first step, set $\\beta = 0$, $\\rho = g^{T}z$, else set $\\beta = \\frac{g^{T}z}{\\rho}$, $\\rho = g^T{z}$.\n",
    "    7. Update the step direction: $t = \\beta t + z$.\n",
    "    8. Compute $\\tau = t^{T}J^{T}WJt$, $\\omega = t^{T}J^{T}W(x - y)$\n",
    "    9. Compute initial approximation for the step length, $\\alpha = \\frac{\\omega}{\\tau}$.\n",
    "    10. Compute $Q^{(2)} = Q(max(f + \\alpha t, 1))$. $f$ is calculated as show in step 3.1/A \n",
    "    11. If $Q^{(2)} < Q^{(1)}$, compute nonlinearity-corrected step length as: $\\alpha = \\frac{\\alpha}{(2 - (Q^{(1)} - Q^{(2)})\\frac{\\tau}{\\omega^2})}$\n",
    "    12. Else, repeatedly try decreasing $\\alpha$, computing $Q^{(2)} = Q(max(f + \\alpha t, 1))$, until $Q^{(2)} < Q^{(1)}$.\n",
    "    13. If it was impossible to satisfy $Q^{(2)} < Q^{(1)}$, go to Step 2.\n",
    "4. Update inverse preconditioning. Denote indexes $n$ of *nonviolating* ($f_n > I_n$) constrained factor elements by $u$, and indexes of violating ($f_n = I_n$) constrained factor elements by $v$.\n",
    "    1. Increase $c_u$, constrained by $c_u \\le 1$.\n",
    "    2. Decrease $c_v$, constrained by $c_v \\ge \\epsilon$.\n",
    "    3. Decrease $t_v$, constrained by $t_v \\ge \\epsilon$.\n",
    "5. Write monitoring output, test for convergence.\n",
    "    1. Output to screen and to log file $Q^{(2)}$ and $\\rho$, that is, the goodness-of-fit and the squared length of the preconditioned gradient.\n",
    "    2. If $|Q^{(1)} - Q^{(2)}| < e$ ($e$ and $k$ are user-specified parameters), and if this condition has been valid in $k$ consecutive steps, assume convergence and go to the end, Step 7.\n",
    "    3. If the maximum iteration count is exceeded, go to the end, Step 7.\n",
    "6. Test for continuing this CG sequence.\n",
    "    1. If convergence is slowing down, and/or the user-specified restart limits allow it, go back to initialiing anothe rCG sequence, Step 2.\n",
    "    2. Otherwise go back to performing the next CG step in the current sequence, Step 3.\n",
    "7. The $f_n$ are the solution. Write the results. If the user has requested so, compute and write the approximate Hessian matrix $J^{T}WJ$, the exact Hessian (E8.1), or the weighted Jacobian sparse matrix $W^\\frac{1}{2}J$ (for computing these matrices, first convert the Jacobian table into the Jacobian matrix. End the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9043ae9-cd91-4300-8515-d323a655c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src.data.datahandler import DataHandler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65d30e12-b044-415d-9443-a1217b695b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = os.path.join(\"D:\\\\\", \"projects\", \"nmf_py\", \"data\", \"Dataset-BatonRouge-con.csv\")\n",
    "uncertainty_file = os.path.join(\"D:\\\\\", \"projects\", \"nmf_py\", \"data\", \"Dataset-BatonRouge-unc.csv\")\n",
    "output_path = os.path.join(\"D:\\\\\", \"projects\", \"nmf_py\", \"output\", \"BatonRouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6581a4f8-cdf3-4368-ab41-be65156d8688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23-May-23 11:12:31 - Input and output configured successfully\n"
     ]
    }
   ],
   "source": [
    "dh = DataHandler(\n",
    "        input_path=input_file,\n",
    "        uncertainty_path=uncertainty_file,\n",
    "        output_path=output_path,\n",
    "        index_col='Date'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15a9650a-6270-48ff-9bd9-41cbc5169981",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = dh.input_data_processed\n",
    "U = dh.uncertainty_data_processed\n",
    "\n",
    "weights = 1/np.sqrt(U)\n",
    "\n",
    "m, n = V.shape\n",
    "n_components = 4\n",
    "seed = 42\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "V_avg = np.sqrt(np.mean(V, axis=0) / n_components)\n",
    "H = V_avg * rng.standard_normal(size=(n_components, n)).astype(V.dtype, copy=False)\n",
    "H = np.abs(H)\n",
    "\n",
    "V_avg2 = np.sqrt(np.mean(V, axis=1) / n_components)\n",
    "V_avg2 = V_avg2.reshape(len(V_avg2), 1)\n",
    "W = np.multiply(V_avg2, rng.standard_normal(size=(m, n_components)).astype(V.dtype, copy=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f07ba1ef-9a1e-424c-ba28-c32de00f20b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307,)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the coefficients for inverse preconditioning\n",
    "c = np.ones(shape=(m))\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d140a2cf-d1b6-4e60-af44-4e489e1316c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 41)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing the Jacobian (Step 2.2)\n",
    "j = np.square((V - np.matmul(W, H))/U)\n",
    "j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43f5e63e-b528-43fd-84f6-1cf70ee32d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 41)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preconditioning coefficients (Step 2.2)\n",
    "p = []\n",
    "for i in range(n):\n",
    "    p_n = 1 / np.sum(weights * j[i]**2, axis=1)    # axis=1 => (41, 307), axis=0 => (41, 41)\n",
    "    p.append(p_n)\n",
    "p = np.array(p).T\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f0e956f8-cc6e-4a17-bcbd-12d4f4d39d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 4, 41)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute SE factors f_h (Step 3.1)\n",
    "f = []\n",
    "_h = np.zeros(shape=H.shape)\n",
    "_w = np.zeros(shape=W.shape)\n",
    "for i in range(m):\n",
    "    fi = []\n",
    "    for k in range(n_components):\n",
    "        fk = []\n",
    "        wk = W[i, k]\n",
    "        _w[i, k] = wk\n",
    "        for j in range(n):\n",
    "            hj = H[k, j]\n",
    "            _h[k, j] = hj\n",
    "            fk.append(wk *hj)\n",
    "        fi.append(fk)\n",
    "    f.append(fi)\n",
    "f = np.array(_f)\n",
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38e9e4bd-89b9-4ece-a235-a465084e0438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309548.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute current fit y_m (Step 3.2)\n",
    "y = np.matmul(W, H)\n",
    "Q1 = np.sum(weights * ((V - y)**2))\n",
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67f54cb9-4571-4043-af68-ba4032923d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the components of the Jacobian (Step 3.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ed1a9d7c-a179-4b0d-a04d-4a7404a89e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.3191492e-04,  1.9877819e+00, -3.3903696e+02, ...,\n",
       "         2.0886194e-02,  1.6315260e+01,  3.6491001e-01],\n",
       "       [ 1.2922232e+02,  2.6506693e+02,  3.7786832e+02, ...,\n",
       "         3.1551428e+02,  5.4215935e+01,  5.1014882e-01],\n",
       "       [ 6.7611023e+02,  7.8001135e+02,  1.5131453e+03, ...,\n",
       "         1.5440063e+03,  4.5510075e+01,  5.3064883e-01],\n",
       "       ...,\n",
       "       [ 1.0032913e+03,  4.5623413e+02,  1.2805981e+02, ...,\n",
       "         2.2779692e+02,  4.0964054e+01,  3.4915167e-01],\n",
       "       [ 8.9038501e+02,  1.1491959e+03,  1.5379944e+02, ...,\n",
       "         6.5550232e+02,  9.2901901e+01,  4.8890892e-01],\n",
       "       [ 2.5032963e+01,  1.0410875e+02,  1.9818988e+02, ...,\n",
       "         8.5854813e+01, -2.2706806e+01,  3.8489667e-01]], dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the gradient (Step 3.4)\n",
    "mi = 0                     # mi=0->m\n",
    "\n",
    "g = []\n",
    "for i in range(m):\n",
    "    Wi = np.diagflat(weights[i])\n",
    "    r = (V[i] - y[i])\n",
    "    r = r.reshape(len(r), 1)\n",
    "    wr = Wi * r\n",
    "    gi = np.matmul(j[i], wr)\n",
    "    g.append(gi)\n",
    "g = np.array(g)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c9d683d-a2ea-4215-aea6-6a4f94ca7c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 41)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform gradient (Step 3.5)\n",
    "_c = c.reshape(len(c), 1)\n",
    "z = np.multiply(_c, np.multiply(p, g))\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3b4aa099-5219-4ab7-a85d-58bc3face4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 41)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if first step rho = 0 (Step 3.6 option 1)\n",
    "beta = 0\n",
    "rho = np.matmul(g.T, z)\n",
    "rho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1783151c-71c7-4629-9181-efc7d75ca639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 41)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# else (Step 3.6 option 2)\n",
    "rho2 = rho\n",
    "beta2 = np.matmul(g.T, z)/rho2\n",
    "rho2 = np.matmul(g.T, z)\n",
    "beta2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "016d1f81-63bb-4d84-9a6a-916f534983b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 41)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the accumulated step direction (Step 3.7)\n",
    "t0 = np.ones(shape=V.shape)\n",
    "t = beta * t0 + z\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3b23b054-6fa6-49c5-b159-3b48526d5b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.28755634e-27, 7.16795278e-11, 3.63778089e-08, ...,\n",
       "        1.04994578e-22, 6.35353560e-16, 3.34495543e-18],\n",
       "       [3.99184104e-08, 9.35080555e-04, 3.10771073e-08, ...,\n",
       "        2.43210919e-08, 7.37150575e-14, 8.25843785e-17],\n",
       "       [1.07842215e-05, 2.29371315e-02, 1.73940801e-06, ...,\n",
       "        2.20582297e-06, 9.92332512e-14, 5.65592506e-17],\n",
       "       ...,\n",
       "       [1.15183197e-05, 3.64476111e-03, 1.35049354e-09, ...,\n",
       "        1.80147751e-08, 1.24755936e-14, 7.43426273e-18],\n",
       "       [1.22959701e-05, 7.91438051e-02, 1.26532217e-09, ...,\n",
       "        2.41504241e-07, 1.58244516e-13, 1.31232166e-17],\n",
       "       [9.29818019e-11, 5.15299282e-05, 9.61618513e-09, ...,\n",
       "        5.23400134e-10, 4.98937633e-14, 1.86001696e-17]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute tau (Step 3.8)\n",
    "tau = []\n",
    "for i in range(m):\n",
    "    wi = np.diagflat(weights[i])\n",
    "    ti = t[i]\n",
    "    ji = j[i]\n",
    "    tau0 = np.multiply(ji, ti)\n",
    "    tau1 = np.matmul(wi, tau0)\n",
    "    tau2 = np.multiply(ji.T, tau1)\n",
    "    _tau = np.multiply(ti.T, tau2)\n",
    "    tau.append(_tau)\n",
    "tau = np.array(tau)\n",
    "tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ec8dcf89-1f2b-4bda-9c8c-277fd80d68cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.03354162e-16, 4.56243365e-06, 2.79573544e-04, ...,\n",
       "        1.13544109e-12, 3.20615795e-07, 5.80442738e-08],\n",
       "       [6.00040702e-04, 1.59200330e-01, 7.27560222e-04, ...,\n",
       "        5.59015485e-04, 1.11770197e-05, 4.29426831e-07],\n",
       "       [1.10568391e-02, 1.13131020e+00, 5.75572249e-03, ...,\n",
       "        6.61488084e-03, 4.69600887e-06, 2.90549784e-07],\n",
       "       ...,\n",
       "       [8.97126859e-03, 1.86226922e-01, 3.89385108e-05, ...,\n",
       "        1.34288192e-04, 1.70516355e-06, 4.90984830e-08],\n",
       "       [1.20407974e-02, 1.76166575e+00, 5.77115798e-05, ...,\n",
       "        1.12720801e-03, 1.02914317e-05, 1.01500942e-07],\n",
       "       [1.62863684e-05, 2.54675180e-02, 2.35751490e-04, ...,\n",
       "        4.74775509e-05, 1.43387941e-06, 1.51962661e-07]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute omega (Step 3.8)\n",
    "omega = []\n",
    "for i in range(m):\n",
    "    wi = np.diagflat(weights[i])\n",
    "    ti = t[i]\n",
    "    ji = j[i]\n",
    "    ri = (V[i] - y[i])\n",
    "    omega0 = np.matmul(wi, ri)\n",
    "    omega1 = np.multiply(ji.T, omega0)\n",
    "    _omega = np.multiply(ti.T, omega1)\n",
    "    omega.append(_omega)\n",
    "omega = np.array(omega)\n",
    "omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "60dcda44-e4a4-4742-b39e-bcfecc9208fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.90937582e+11, 6.36504424e+04, 7.68527715e+03, ...,\n",
       "        1.08142831e+10, 5.04625793e+08, 1.73527795e+10],\n",
       "       [1.50316783e+04, 1.70253065e+02, 2.34114525e+04, ...,\n",
       "        2.29848021e+04, 1.51624649e+08, 5.19985545e+09],\n",
       "       [1.02527930e+03, 4.93222181e+01, 3.30901228e+03, ...,\n",
       "        2.99882671e+03, 4.73229368e+07, 5.13708687e+09],\n",
       "       ...,\n",
       "       [7.78869559e+02, 5.10944110e+01, 2.88328004e+04, ...,\n",
       "        7.45433631e+03, 1.36679953e+08, 6.60435133e+09],\n",
       "       [9.79247452e+02, 2.22590479e+01, 4.56101863e+04, ...,\n",
       "        4.66744601e+03, 6.50349976e+07, 7.73445604e+09],\n",
       "       [1.75156515e+05, 4.94227702e+02, 2.45161139e+04, ...,\n",
       "        9.07098562e+04, 2.87386501e+07, 8.16996108e+09]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute initial approximation for the step length (Step 3.9)\n",
    "alpha = omega / tau\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b7e8da7e-a41c-4601-8630-93bc308d5395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.11052010e-01,  1.33129102e+00,  1.20492272e+00, ...,\n",
       "         1.91288744e+00,  1.62632098e+01,  2.76572546e+03],\n",
       "       [ 3.97332746e-01, -5.53582490e-03, -6.50607721e-01, ...,\n",
       "        -4.62248521e-01,  3.64149360e+01,  4.37808810e+03],\n",
       "       [-9.26325394e-01, -2.09863118e+00, -1.60060021e+00, ...,\n",
       "        -1.64683616e+00,  5.56339440e-01,  2.79892413e+03],\n",
       "       ...,\n",
       "       [-8.06893268e-01, -6.73559948e-01, -7.42896794e-02, ...,\n",
       "        -1.56420443e-01,  2.44207083e+00,  9.21232754e+02],\n",
       "       [-1.05487798e+00, -2.22889983e+00, -9.52063112e-02, ...,\n",
       "        -6.08232258e-01, -7.72598865e+00,  1.59024396e+03],\n",
       "       [ 1.37923379e+00,  1.08720918e+00, -1.55451185e-01, ...,\n",
       "         3.78035104e-01,  1.54364336e+01,  3.23332299e+03]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update f\n",
    "fh = np.matmul(W, H)\n",
    "new_f = fh + alpha * t\n",
    "new_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "977df938-eb72-42d1-9cb3-b78df1d98639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 4)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Issue is that this process is for updating the product and not the composing matrices W and H\n",
    "# Rewrite the process to target one of the composing matrices then switch\n",
    "\n",
    "# Keep H constant and update W\n",
    "import copy\n",
    "\n",
    "\n",
    "W0 = copy.copy(W)\n",
    "H0 = copy.copy(H)\n",
    "\n",
    "X = copy.copy(V)\n",
    "U = copy.copy(U)\n",
    "\n",
    "weights = copy.copy(weights)\n",
    "W0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e5cafe50-5cd0-4aef-aa90-6d8d7b3099eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (41,) (4,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [160], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m p \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m):\n\u001b[1;32m----> 4\u001b[0m     _p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (np\u001b[38;5;241m.\u001b[39msum(\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mW0\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m))\n\u001b[0;32m      5\u001b[0m     p\u001b[38;5;241m.\u001b[39mappend(_p)\n\u001b[0;32m      6\u001b[0m p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(p)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (41,) (4,) "
     ]
    }
   ],
   "source": [
    "# Calcualte preconditioning coefficients (Step 2.2)\n",
    "\n",
    "n_i = 0\n",
    "\n",
    "\n",
    "p_i = 1.0 / \n",
    "\n",
    "\n",
    "p = []\n",
    "for i in range(m):\n",
    "    _p = 1 / (np.sum(weights[i] * W0[i]**2))\n",
    "    p.append(_p)\n",
    "p = np.array(p)\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "80897490-eb44-4cb0-aaf4-9878812a5343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.53744906,   1.1851981 ,   1.2112601 , ...,   1.324988  ,\n",
       "          6.3466654 ,   5.512077  ],\n",
       "       [  0.3275335 ,  -0.10779054,  -0.6956849 , ...,  -0.50297207,\n",
       "          5.1563826 ,   1.0174291 ],\n",
       "       [ -0.9430924 ,  -2.170167  ,  -1.6131871 , ...,  -1.6596838 ,\n",
       "         -4.3267317 , -13.820197  ],\n",
       "       ...,\n",
       "       [ -0.8138578 ,  -0.6944158 ,  -0.08305673, ...,  -0.16081484,\n",
       "         -3.2473483 ,  -7.4857893 ],\n",
       "       [ -1.0681205 ,  -2.263022  ,  -0.11232104, ...,  -0.61625844,\n",
       "        -14.930397  , -15.483709  ],\n",
       "       [  1.2652775 ,   0.96630913,  -0.18461367, ...,   0.32787272,\n",
       "         17.25121   ,   7.7065096 ]], dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute SE factors (Step 3.1)\n",
    "\n",
    "\n",
    "# Compute the current fit (Step 3.2)\n",
    "y_m = np.matmul(W0, H0)\n",
    "y_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6045dc88-53bb-4684-9747-1c0591b2b9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 4)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the gradient (Step 3.4)\n",
    "residuals = X - y_m\n",
    "i = 0\n",
    "\n",
    "Wi = np.diagflat(weights[i])\n",
    "wr = np.matmul(Wi, residuals.T)\n",
    "wr.shape\n",
    "g = np.matmul(H0, wr).T\n",
    "g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a904d236-8479-4466-8d7c-e853036e9eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute transofrmed gradient z (Step 3.5)\n",
    "z = \n",
    "\n",
    "beta0 = 0\n",
    "rho = np.matmul(g.T, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
