{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5686853f-4655-4e79-af04-fe24aac1756e",
   "metadata": {
    "id": "5686853f-4655-4e79-af04-fe24aac1756e"
   },
   "source": [
    "## NMF-PY Workflow\n",
    "\n",
    "The steps in this notebook are intended to replicate the preprocessing, base model building, and base model post-processing steps of PMF5.\n",
    "\n",
    "The error estimation functionality has not yet been implemented in the new code base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b01571c-a954-4399-a913-eeb39cfe91db",
   "metadata": {
    "id": "3b01571c-a954-4399-a913-eeb39cfe91db"
   },
   "outputs": [],
   "source": [
    "# Notebook imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "sys.path.insert(0, \"/content/nmf_py-main\")\n",
    "sys.path.insert(0, \"/content/nmf_py-main/src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbbb442-6b3d-4a6e-a843-855ede16f734",
   "metadata": {
    "id": "2cbbb442-6b3d-4a6e-a843-855ede16f734"
   },
   "source": [
    "#### Sample Dataset\n",
    "The three sample datasets from PMF5 are available for use, but a new dataset can be used in their place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d103181a-dbbe-42df-8fa7-9aa195ef20ed",
   "metadata": {
    "id": "d103181a-dbbe-42df-8fa7-9aa195ef20ed"
   },
   "outputs": [],
   "source": [
    "# Baton Rouge Dataset\n",
    "br_input_file = os.path.join(\"/content/nmf_py-main/data/Dataset-BatonRouge-con.csv\")\n",
    "br_uncertainty_file = os.path.join(\"/content/nmf_py-main/data/Dataset-BatonRouge-unc.csv\")\n",
    "br_output_path = os.path.join(\"/content/nmf_py/data-main/output/BatonRouge\")\n",
    "# Baltimore Dataset\n",
    "# b_input_file = os.path.join(\"data\", \"Dataset-Baltimore_con.txt\")\n",
    "# b_uncertainty_file = os.path.join(\"data\", \"Dataset-Baltimore_unc.txt\")\n",
    "# b_output_path = os.path.join(\"data\", \"output\", \"Baltimore\")\n",
    "# Saint Louis Dataset\n",
    "# sl_input_file = os.path.join(\"data\", \"Dataset-StLouis-con.csv\")\n",
    "# sl_uncertainty_file = os.path.join(\"data\", \"Dataset-StLouis-unc.csv\")\n",
    "# sl_output_path = os.path.join(\"data\", \"output\", \"StLouis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nfcV85xTw56x",
   "metadata": {
    "id": "nfcV85xTw56x"
   },
   "outputs": [],
   "source": [
    "# !unzip /content/nmf_py-main-20231012.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6liOt3ikAIxC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6liOt3ikAIxC",
    "outputId": "a7ecce87-001e-4f2e-cd18-46dc5a703cf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzy-c-means in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: joblib<2.0.0,>=1.2.0 in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (from fuzzy-c-means) (1.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.21.1 in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (from fuzzy-c-means) (1.24.3)\n",
      "Requirement already satisfied: pydantic<2.0.0,>=1.9.0 in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (from fuzzy-c-means) (1.10.8)\n",
      "Requirement already satisfied: tabulate<0.9.0,>=0.8.9 in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (from fuzzy-c-means) (0.8.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (from fuzzy-c-means) (4.65.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.4.0 in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (from fuzzy-c-means) (0.4.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (from pydantic<2.0.0,>=1.9.0->fuzzy-c-means) (4.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (from tqdm<5.0.0,>=4.64.1->fuzzy-c-means) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\dsmith\\anaconda3\\envs\\nmf_py\\lib\\site-packages (from typer<0.5.0,>=0.4.0->fuzzy-c-means) (8.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzy-c-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770385fe-48ab-47c4-bdbb-50bab6950d05",
   "metadata": {
    "id": "770385fe-48ab-47c4-bdbb-50bab6950d05"
   },
   "source": [
    "#### Code Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e368db8a-f7f5-4b5e-b2e0-80921532d121",
   "metadata": {
    "id": "e368db8a-f7f5-4b5e-b2e0-80921532d121"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatahandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataHandler\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnmf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NMF\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_nmf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchNMF\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.data.datahandler import DataHandler\n",
    "from src.model.nmf import NMF\n",
    "from src.model.batch_nmf import BatchNMF\n",
    "from src.data.analysis import ModelAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f532c5-1e71-4966-8edf-e8f68fa0bd57",
   "metadata": {
    "id": "84f532c5-1e71-4966-8edf-e8f68fa0bd57"
   },
   "source": [
    "#### Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2281601e-af6e-43b4-80eb-317ebfaf5ede",
   "metadata": {
    "id": "2281601e-af6e-43b4-80eb-317ebfaf5ede"
   },
   "outputs": [],
   "source": [
    "index_col = \"Date\"                  # the index of the input/uncertainty datasets\n",
    "factors = 6                         # the number of factors\n",
    "method = \"ls-nmf\"                   # \"ls-nmf\", \"ws-nmf\"\n",
    "models = 20                         # the number of models to train\n",
    "init_method = \"col_means\"           # default is column means \"col_means\", \"kmeans\", \"cmeans\"\n",
    "init_norm = True                    # if init_method=kmeans or cmeans, normalize the data prior to clustering.\n",
    "seed = 42                           # random seed for initialization\n",
    "max_iterations = 20000              # the maximum number of iterations for fitting a model\n",
    "converge_delta = 0.1                # convergence criteria for the change in loss, Q\n",
    "converge_n = 10                     # convergence criteria for the number of steps where the loss changes by less than converge_delta\n",
    "verbose = True                      # adds more verbosity to the algorithm workflow on execution.\n",
    "optimized = True                    # use the Rust code if possible\n",
    "parallel = True                     # execute the model training in parallel, multiple models at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90318121-9709-4e67-baf3-8f76432f68ed",
   "metadata": {
    "id": "90318121-9709-4e67-baf3-8f76432f68ed"
   },
   "source": [
    "#### Dataset Selection\n",
    "One of the three sample datasets can be selected or a new cleaned dataset can be used. Datasets should be cleaned, containing no missing data (either dropping missing/NaNs, or interpolating the missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f90ce2-d9d3-42cd-8a30-aa5b0b73fe77",
   "metadata": {
    "id": "16f90ce2-d9d3-42cd-8a30-aa5b0b73fe77"
   },
   "outputs": [],
   "source": [
    "# Loading the Baton Rouge dataset\n",
    "input_file = br_input_file\n",
    "uncertainty_file = br_uncertainty_file\n",
    "output_path = br_output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d605314-c34a-434d-a178-81b6f6b3766d",
   "metadata": {
    "id": "1d605314-c34a-434d-a178-81b6f6b3766d"
   },
   "source": [
    "#### Load Data\n",
    "Assign the processed data and uncertainty datasets to the variables V and U. These steps will be simplified/streamlined in a future version of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c2f332-c4f1-43c6-94ec-7b22d0cbc0ab",
   "metadata": {
    "id": "e4c2f332-c4f1-43c6-94ec-7b22d0cbc0ab"
   },
   "outputs": [],
   "source": [
    "data_handler = DataHandler(\n",
    "    input_path=input_file,\n",
    "    uncertainty_path=uncertainty_file,\n",
    "    index_col=index_col\n",
    ")\n",
    "V, U = data_handler.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412787cb-62cf-4a86-9a2d-f368030e11db",
   "metadata": {
    "id": "412787cb-62cf-4a86-9a2d-f368030e11db"
   },
   "source": [
    "#### Input/Uncertainty Data Metrics and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d28851-eee3-4682-817e-00ce63e5617b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "58d28851-eee3-4682-817e-00ce63e5617b",
    "outputId": "7ec54854-80a4-4e37-c943-20b9366562a3"
   },
   "outputs": [],
   "source": [
    "# Show the input data metrics, including signal to noise ratio of the data and uncertainty\n",
    "data_handler.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac7440-7f97-4b81-a2ac-6e539f294132",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "15ac7440-7f97-4b81-a2ac-6e539f294132",
    "outputId": "53aca77e-640a-4653-cf16-ffa8abde0c49"
   },
   "outputs": [],
   "source": [
    "# Concentration / Uncertainty Scatter plot for specific feature, feature/column specified by index\n",
    "data_handler.data_uncertainty_plot(feature_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c24b313-37ca-412f-b07b-dcd00021773b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "0c24b313-37ca-412f-b07b-dcd00021773b",
    "outputId": "9c85ed60-74f4-49ff-f787-17d26faf66da"
   },
   "outputs": [],
   "source": [
    "# Species Concentration plot comparing features, features/columns specified by index\n",
    "data_handler.feature_data_plot(x_idx=0, y_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964a8c8b-3b57-487c-b7b3-c9f6ca7dad78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "964a8c8b-3b57-487c-b7b3-c9f6ca7dad78",
    "outputId": "ea9d6f8a-ccad-4fc2-f611-a32fa984ab2d"
   },
   "outputs": [],
   "source": [
    "# Species Timeseries, a single or list of features/columns specified by index\n",
    "data_handler.feature_timeseries_plot(feature_selection=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f561829-6c19-4eeb-b8d3-3f83180b9794",
   "metadata": {
    "id": "9f561829-6c19-4eeb-b8d3-3f83180b9794"
   },
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018eb975-f9dd-4e73-bf1d-8c5b696e6dca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "018eb975-f9dd-4e73-bf1d-8c5b696e6dca",
    "outputId": "83e0cfff-00f2-456b-a07f-c23e721b10ad"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Training multiple models, optional parameters are commented out.\n",
    "nmf_models = BatchNMF(V=V, U=U, factors=factors, models=models, method=method, seed=seed, max_iter=max_iterations,\n",
    "                    # init_method=init_method, init_norm=init_norm,\n",
    "                    converge_delta=converge_delta, converge_n=converge_n,\n",
    "                    parallel=parallel, optimized=False,\n",
    "                    # verbose=verbose\n",
    "                   )\n",
    "nmf_models.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa8298-bd0f-4dea-97f9-43a9971303b2",
   "metadata": {
    "id": "23fa8298-bd0f-4dea-97f9-43a9971303b2",
    "outputId": "eb41bcad-e5c8-42f8-ffcd-ec0696017468"
   },
   "outputs": [],
   "source": [
    "# Selet the model to review, by index or the best performing from the collection of models\n",
    "best_model = nmf_models.best_model\n",
    "nmf_model = nmf_models.results[best_model]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef5ff6-a181-4342-a499-860fced9b64b",
   "metadata": {
    "id": "46ef5ff6-a181-4342-a499-860fced9b64b"
   },
   "outputs": [],
   "source": [
    "# Initialize the Model Analysis module\n",
    "model_analysis = ModelAnalysis(datahandler=data_handler, model=nmf_model, selected_model=best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d2bff7-b36a-4837-95a9-1ff2bd90c0fa",
   "metadata": {
    "id": "48d2bff7-b36a-4837-95a9-1ff2bd90c0fa",
    "outputId": "74b285b2-b004-4521-a244-762c3e58ffbb"
   },
   "outputs": [],
   "source": [
    "# Residual Analysis shows the scaled residual histogram, along with metrics and distribution curves. The abs_threshold parameter specifies the condition for the returned values of the function call as those residuals which exceed the absolute value of that threshold.\n",
    "abs_threshold = 3.0\n",
    "threshold_residuals = model_analysis.plot_residual_histogram(feature_idx=0, abs_threshold=abs_threshold)\n",
    "print(f\"List of Absolute Scaled Residual Greather than: {abs_threshold}. Count: {threshold_residuals.shape[0]}\")\n",
    "threshold_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d33c4-51b4-4c1d-b01e-7b9667638e64",
   "metadata": {
    "id": "462d33c4-51b4-4c1d-b01e-7b9667638e64",
    "outputId": "ef20c3f7-bb08-40b0-c38d-e9edf4cf0b07"
   },
   "outputs": [],
   "source": [
    "# The model output statistics for the estimated V, including SE: Standard Error metrics, and 3 normal distribution tests of the residuals (KS Normal is used in PMF5)\n",
    "model_analysis.calculate_statistics()\n",
    "model_analysis.statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d23a88-47f5-4692-ba9b-07e8630d5486",
   "metadata": {
    "id": "69d23a88-47f5-4692-ba9b-07e8630d5486",
    "outputId": "2fd58e3a-55a8-4dc1-c5f4-3b01988eaaa2"
   },
   "outputs": [],
   "source": [
    "# Model feature observed vs predicted plot with regression and one-to-one lines. Feature/Column specified by index.\n",
    "model_analysis.plot_estimated_observed(feature_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a0280-d275-46d5-973e-48fa55fd51af",
   "metadata": {
    "id": "102a0280-d275-46d5-973e-48fa55fd51af",
    "outputId": "055d81da-3463-4719-9b9a-40d5d818d38c"
   },
   "outputs": [],
   "source": [
    "# Model feature timeseries analysis plot showing the observed vs predicted values of the feature, along with the residuals shown below. Feature/column specified by index.\n",
    "model_analysis.plot_estimated_timeseries(feature_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da54785-9c7f-4396-b776-f086612ace02",
   "metadata": {
    "id": "2da54785-9c7f-4396-b776-f086612ace02",
    "outputId": "9254694b-92be-49b7-e262-7813e6489d0c"
   },
   "outputs": [],
   "source": [
    "# Factor profile plot showing the factor sum of concentrations by feature (blue bars), the percentage of the feature as the red dot, and in the bottom plot the normalized contributions by date (values are resampled at a daily timestep for timeseries consistency).\n",
    "# Factor specified by index.\n",
    "model_analysis.plot_factor_profile(factor_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e332d6-75b2-4682-ba27-612dfaf26b27",
   "metadata": {
    "id": "e8e332d6-75b2-4682-ba27-612dfaf26b27",
    "outputId": "901f1411-10e5-41b4-82cb-142f3d4a99ca"
   },
   "outputs": [],
   "source": [
    "# Model factor fingerprint specifies the feature percentage of each factor.\n",
    "model_analysis.plot_factor_fingerprints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8bb85b-b48e-4031-b861-d6f6af5ad090",
   "metadata": {
    "id": "4c8bb85b-b48e-4031-b861-d6f6af5ad090",
    "outputId": "d4795411-5545-49ff-98a1-2b184dadd4fa"
   },
   "outputs": [],
   "source": [
    "# Factor G-Space plot shows the normalized contributions of one factor vs another factor. Factor specified by index.\n",
    "model_analysis.plot_g_space(factor_1=2, factor_2=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8514eed-0747-49b0-b387-ce3379213a2e",
   "metadata": {
    "id": "5afced49-c9ff-4a44-9558-e327d07d46bc",
    "outputId": "499ec5ca-8d55-4537-a069-a7b004821e1c"
   },
   "outputs": [],
   "source": [
    "# Factor contribution pie chart shows the percentage of factor contributions for the specified feature, and the corresponding normalized contribution of each factor for that feature (bottom plot). Feature specified by index.\n",
    "model_analysis.plot_factor_contributions(feature_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e479211-fc1d-46d8-a84a-13e339143c1c",
   "metadata": {
    "id": "5afced49-c9ff-4a44-9558-e327d07d46bc",
    "outputId": "499ec5ca-8d55-4537-a069-a7b004821e1c"
   },
   "outputs": [],
   "source": [
    "# New Graphic: Factor Profile Composition Radar Graph\n",
    "model_analysis.plot_factor_composition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be971709-def7-4528-85f2-b5a1dd7e8506",
   "metadata": {
    "id": "5afced49-c9ff-4a44-9558-e327d07d46bc",
    "outputId": "499ec5ca-8d55-4537-a069-a7b004821e1c"
   },
   "outputs": [],
   "source": [
    "# New Graphic: Factor Contribution Surface Plot\n",
    "factor_idx = 1\n",
    "model_analysis.plot_factor_surface(factor_idx=factor_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccba89f-ec29-4791-b221-ecfbd4f15009",
   "metadata": {
    "id": "5aa9ec8d-6aef-4803-8646-b9e0e35e3408"
   },
   "source": [
    "### Error Estimation - Displacement\n",
    "\n",
    "The displacement method for error estimation works by make slight adjustments to the factor profile values, individually, until a specific change in the loss value (dQ) is reached. There are 4 dQ values that are targetted, dQ = 4, 8, 16, 32. \n",
    "\n",
    "The target dQ value is run for both an increase and decrease in the factor profile value, a single value in the factor profile matrix at a time. The change in factor profile is found by running a modified binary search to identify the value change within a small threshold, 0.1 of the target dQ. The value search is stopped if the change in the factor profile value is less than 1e-8, in the instance that decreasing a factor profile value already near zero.\n",
    "\n",
    "Once the change in the factor profile value is found that produces the target dQ, both increasing and decreasing, the modification to the H matrix is used as an initial guess for retraining a NMF model. The W matrix is reinitialized, using the original base model seed, and the model is trained to convergence. \n",
    "\n",
    "The resulting model factor profile is checked to see if any factors swapped base upon the highest factor correlation with the base model factors. The output shows the swap %, based upon the number of retrained models where that factor was modified and the number of times a swap was detected.\n",
    "\n",
    "The factor profile plot shows the variability in the factor profile feature values that correspond to the dQ target values, default shown in the plots is for a dQ=4. The last plot show the factor feature contribution variability based upon the same changes to the H matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd3b97f-f675-4eda-8fb8-db22fbbcbfd2",
   "metadata": {
    "id": "5aa9ec8d-6aef-4803-8646-b9e0e35e3408"
   },
   "outputs": [],
   "source": [
    "# Import Error Estimation Displacement Method\n",
    "from src.error.displacement import Displacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8cb683-1176-40d8-a46b-a9be537838ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Displacement method, passing in the results of the batch nmf run and the features labels from the data handler.\n",
    "disp = Displacement(nmf=nmf_model, feature_labels=data_handler.features, model_selected=best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b61601-2b09-4066-856d-e3895a684209",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Execute the displacement model, which will test both increasing and decreasing changes to the individual values of H for all dQ targets. Results are then compiled and prepared.\n",
    "disp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492f1b9d-2309-4034-b379-264a0909605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The swap table shows the percentage of times a factor was found to be more highly correlated as a result of the change in the factor feature value. This percentage is the number of times that a specific factor swapped after a model was retrained.\n",
    "# The largest change in the dQ value is the largest difference (both from increasing and decreasing changes to the factor feature values) between a retrained model and the base model loss value.\n",
    "disp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0abf217-b12f-4a58-bb9c-e0f81a089405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results for a specific factor can be plotted, showing both the variability in the profile(%) and contribution for a given dQ value.\n",
    "factor_i = 1\n",
    "disp.plot_results(factor=factor_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12fc496-9d20-4aeb-afb7-c50968d2fb52",
   "metadata": {},
   "source": [
    "### Error Estimation - Bootstrap\n",
    "\n",
    "The bootstrap method used is the block bootstrap method for time-series data. Here the initial dataset is broken into chunks of a specified size, containing sequential samples, and randomly added to a bootstrap dataset until the bootstrap dataset is the same size as the initial dataset.\n",
    "\n",
    "The recommended block size calculation feature has not yet been implemented. \n",
    "\n",
    "The aim of the bootstrap method is to quantify the variability in the factor profiles and contributions when the order of the datasets have been shuffled, resampled. In this case the block bootstrap method is the default method, while the full bootstrap method can be used by setting the block parameter in the run function to false, i.e. bs.run(block=False). The blocks are randomly selected with replacement, allowing for the same block to be added to the bs dataset more than once. The final selected block is reduced in size until the bs dataset is exactly the same as the initial dataset. \n",
    "\n",
    "The resampling is completed a specified number of times, set by bootstrap_n. During each bootstrap run, the initial datasets are resampled (both the data and uncertainty datasets are resampled using the same indeces) and used to retrain a NMF model. The NMF model uses the resampled data and uncertainty data, the base model H matrix and the base model random seed. W is reinitialized and the model is trained to convergence. The resulting factor contributions, $V'_{bs}$ are mapped to the base model $V'_{base}$, where the correlation between all combinations of the factor contributions are checked. The mapping between the highest correlation is then noted, if the correlation is above the user specified threshold (default=0.6), and the results are shown in the summary statistics. The summary statistics also include metrics for the distribution of the bootstrap model results to compare against the base model results, these are shown as tables for each factor in the summary statistics.\n",
    "\n",
    "The results of all the bootstrap runs are compiled to provide a distribution for each factor/feature percentage and contribution, these are shown in the plotted results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505e9f0-ca12-4cca-8870-a6b430e3dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Bootstrap Error Estimation Method\n",
    "from src.error.bootstrap import Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c571d25e-e137-4929-a3c6-ebc58adc189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap input parameters\n",
    "# Some parameters are simply reassigned for clarity.\n",
    "model_selected = nmf_models.best_model              # the model selected to be the base model for the Bootstrap method, here chosen as the best performing model from the batch nmf run.\n",
    "nmf_model = nmf_models.results[model_selected]      # The selected model NMF object.\n",
    "feature_labels = data_handler.features              # The list of feature names/labels\n",
    "\n",
    "bootstrap_n = 20                                    # The number of bootstrap runs to complete\n",
    "block_size = data_handler.optimal_block             # Calculates an optimal block size from the Politis and White 2004 algorithm (used in PMF5)\n",
    "threshold = 0.6                                     # The r-correlation threshold\n",
    "seed = seed                                         # The random seed used for random selection of the bootstrap blocks.\n",
    "print(f\"Optimal BS block size: {data_handler.optimal_block}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a6275-b39c-48c4-b7a1-6906753ee453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the bootstrap object\n",
    "bs = Bootstrap(nmf=nmf_model, feature_labels=feature_labels, model_selected=model_selected, bootstrap_n=bootstrap_n, block_size=block_size, threshold=threshold, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1dd26-741f-4b30-bcd4-135e0031d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Execute the bootstrap runs with default parameters\n",
    "bs.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a056896d-532e-4d26-a203-37aa4a997b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the output summary of all the bootstrap runs.\n",
    "bs.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccb51bc-f6e0-424d-b4a3-043ff64606d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of the bootstrap runs for a specific factor, showing the variability in percentage and concentration for each feature of the specified factor.\n",
    "factor_i = 1\n",
    "bs.plot_results(factor=factor_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7feec5e-8f4e-4465-ab82-ad13f2d43b40",
   "metadata": {},
   "source": [
    "### Error Estimation - Bootstrap-Displacement\n",
    "\n",
    "The bootstrap-displacement (BS-DISP) method is a combination of the boostrap and displacement methods. An existing BS instance can be used, or a new BS instance will be created.\n",
    "\n",
    "The BS-DISP method runs a BS instance and for each model in the BS run, DISP is run for each of the features specified or all by default. The results are similar to the DISP results by are aggregated across all bootstrap runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221d4a3-3878-4c4c-863e-400a22f1e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.error.bs_disp import BSDISP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e6d6d-5509-4dfc-b4a0-19755fa46220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap input parameters (Shared with BS-DISP)\n",
    "model_selected = nmf_models.best_model              # the model selected to be the base model for the Bootstrap method, here chosen as the best performing model from the batch nmf run.\n",
    "nmf_model = nmf_models.results[model_selected]      # The selected model NMF object.\n",
    "feature_labels = data_handler.features              # The list of feature names/labels\n",
    "\n",
    "bootstrap_n = 10                                    # The number of bootstrap runs to complete\n",
    "block_size = data_handler.optimal_block             # Calculates an optimal block size from the Politis and White 2004 algorithm (used in PMF5)\n",
    "threshold = 0.6                                     # The r-correlation threshold\n",
    "seed = seed                                         # The random seed used for random selection of the bootstrap blocks.\n",
    "\n",
    "# Displacement input parameters (Shared with BS-DISP)\n",
    "threshold_dQ = 0.1\n",
    "max_search = 50\n",
    "features = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab8ffe-6563-4a3c-b1d6-a459dcf215bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BS-DISP with the BS and DISP parameters\n",
    "bsdisp = BSDISP(nmf=nmf_model, feature_labels=feature_labels, model_selected=model_selected, bootstrap_n=bootstrap_n, block_size=block_size, threshold=threshold, max_search=max_search, threshold_dQ=threshold_dQ, features=features, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2ad1d0-6c71-4427-bbf4-5f094d919983",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Execute the BS-DISP instance, which will first run BS (if required) then will run DISP for each BS model.\n",
    "# parallel = False (CPU times: total: 1h 21min 25s, Wall time: 10min 13s)\n",
    "bsdisp.run(parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c07e373-e5a2-42da-bbfb-75f00b39d1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the summary table and general metrics\n",
    "bsdisp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c3bb7-9834-4665-8173-49c09059a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the BS-DISP results, the profile and contribution boxplots for a specific factor.\n",
    "factor_i = 1\n",
    "bsdisp.plot_results(factor=factor_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b623a8-914c-4e2b-875d-330c07c67a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The overall error summary can be shown through the follow method that will take in an existing bootstrap and displacement object and plot the error estimation for a given factor.\n",
    "from src.error.error import Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2480e2-f498-4440-b1c4-74b6b1cf6a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in the previously completed bootstrap and displacement instances\n",
    "error = Error(bs=bs, disp=disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac5a915-351c-464e-892c-dff96d9cd773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the error estimation of the concentration for a specified factor.\n",
    "factor_i = 1\n",
    "error.plot_summary(factor=factor_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc534aa4-7a5a-44fe-a641-623e0854854d",
   "metadata": {},
   "source": [
    "### Constrained Model\n",
    "\n",
    "The constrained model provides the functionality for a user to use their prior knowledge about the source profiles to place limits and constraints on factor elements of the solution.\n",
    "\n",
    "The constrained model allows for two different options for placing these limits on the values of the solution, expressions and constraints. Constraints allow for a user to set precise limits on the value of a factor element, through several different constraint types. Expressions allow for the user to define how a factor element value is related to one or more other factor element values. These expressions are limited by the change in Q as a results of the new factor element values.\n",
    "\n",
    "Both constraints and expressions are evaluated at every iteration of the constrained model run, with expressions occuring first and the constraints being applied second. Constraints are either determined exactly prior to running the model, limited by a bounds, or are calculated by a value that results in a target dQ. Expressions are dynamic as the values and sum of the expression can change from one iteration to the next.\n",
    "\n",
    "Expressions are evaluated collectively as a set of linear equations, converted into matrix form. Such that:</br></br>\n",
    "$$c1*x1 + c2*x2 = 0$$\n",
    "$$c3*x3 - c4*x4 + c5*x5 = 0$$\n",
    "$$c6*x2 + c7*x5 = 0$$\n",
    "is equivalent to\n",
    "$$\\begin{bmatrix}\n",
    "c1 & c2 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & c3 & -c4 & c5 \\\\\n",
    "0 & c6 & 0 & 0 & c7 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$$ \n",
    "\n",
    "The matrix of expressions is evaluated at each iteration to account for updates to the factor elements, both from the constraints and the update algorithm.\n",
    "\n",
    "A completed constrained model run will provided a constrained model which can then be used on any of the error estimation methods, by passing the .constrained_model (NMF) as the base model was originally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a49b9-07c8-4871-8030-afafd7214818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Constrained Model module\n",
    "from src.rotational.constrained import ConstrainedModel\n",
    "\n",
    "cm = ConstrainedModel(base_model=nmf_model, data_handler=data_handler, softness=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee24d358-e387-4a24-9113-850607de0a55",
   "metadata": {},
   "source": [
    "#### Adding Constraints\n",
    "There are 6 different constraint types available:</br>\n",
    "\"pull down\", \"pull up\", \"pull to value\", \"set to zero\", \"set to base value\", \"define limits\"\n",
    "\n",
    "The target of the constraint can be either \"feature\" (H) or \"sample\" (W)\n",
    "\n",
    "Additional parameters are available in the add_constraint method depending upon the constraint type specified:</br>\n",
    "'define limits' requires a min_value and a max_value parameter to be provided.</br>\n",
    "'pull to value' requires a target_value and dQ parameter to be provided.</br>\n",
    "'pull down' and 'pull up' require the dQ parameter to be provided.</br>\n",
    "\n",
    "Constraints are added to a constrained model by the .add_constraint() method. A factor element can only have one constraint.</br>\n",
    "Note that the index of the matrices are 'feature'=(index of factor, index of feature) and 'sample'=(index of sample, index of factor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f292c-a2dd-4c6f-a3fe-115fdc40af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 'set to zero 'constraint on the Factor-Feature matrix (H) index (0, 3)\n",
    "cm.add_constraint(constraint_type=\"set to zero\", index=(0,3), target=\"feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0f0342-4393-46a4-9a45-2f64d9f68198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 'define limits' constraint\n",
    "cm.add_constraint(constraint_type=\"define limits\", index=(2,10), target=\"feature\", min_value=0.1, max_value=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd39123b-f3a1-4d1d-a148-495ae47dd823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'pull up' and 'pull down' constraints\n",
    "cm.add_constraint(constraint_type=\"pull up\", index=(2, 15), target=\"feature\", dQ=100)\n",
    "cm.add_constraint(constraint_type=\"pull down\", index=(5, 1), target=\"feature\", dQ=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e64f707-0fd3-411c-bc94-df5b604ed48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'set to base value' constraint\n",
    "cm.add_constraint(constraint_type='set to base value', index=(3, 3), target=\"feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946b4dae-4c65-4fbb-b431-178d162da580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'pull to value' constraint\n",
    "cm.add_constraint(constraint_type='pull to value', index=(4, 20), target=\"feature\", target_value=2.5, dQ=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90022b74-9d26-43db-8011-003f31ab24c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all constraints\n",
    "cm.list_constraints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76fccd5-eb1b-4018-9a79-d6cb634cfd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraints can be remove before training the model with 'constraint_model.remove_constraint(constraint_label=LABEL)' where LABEL is the string 'factor:I|feature:J', also shown when the constraints are listed.\n",
    "cm.remove_constraint(constraint_label='factor:0|feature:3')\n",
    "cm.list_constraints()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2605587-a4fc-458b-b664-025b954661a4",
   "metadata": {},
   "source": [
    "#### Adding Expressions\n",
    "An expression is an equation involving 2 or more factor elements (from either W or H) where each factor element has a coefficient and the equation equals 0.</br>\n",
    "\n",
    "A factor element is defined by the string 'factor:F|feature:K' or 'factor:F|sample:J' where F, K, J are indecies. The factor element is defined inside of [ ], such as '[factor:1|feature:1]'.</br> \n",
    "\n",
    "A coefficient is placed in front of the factor element, and must be present (set to 1.0 in those cases). The coefficient of a factor element is structured like '10.0*[factor:2|feature:10]'</br>\n",
    "These coefficient/factor element terms are bounded by () and between multiple terms can be the +/- operator. The equations are all equal to zero.\n",
    "\n",
    "The expression string contains two components, the expression itself and a number that specifies the dQ limit.\n",
    "\n",
    "Examples of expression strings:\n",
    "\n",
    "\"(0.66*[factor:1|feature:2])-(4.2*[factor:2|feature:4])=0,250\"</br>\n",
    "\"(0.35*[factor:0|feature:3])-(2.0*[factor:1|feature:3])-(3.7*[factor:3|feature:4])=0,250\"</br>\n",
    "\"(3.2*[factor:2|feature:4])+(1.2*[factor:3|feature:10])+(0.1*[factor:1|feature:3])+(20.0*[factor:4|feature:3])-(10.7*[factor:5|feature:4])=0,250\"</br>\n",
    "\n",
    "The expressions are solved at each iteration where the equation is set to equal the sum of all factor elements. These expressions are solved as a single linear equation, with the sum of all dQ limits used to reduce the change from the original values to the solved target values.\n",
    "\n",
    "There is currently no limit on the number of expressions or the number of times a factor element can be in an expression. A factor element can be in both a constraint and one or more expressions.\n",
    "\n",
    "During each iteration of the constained model training method, the expressions are evaluated first and then the constraints are applied. These constraint and expressions results are used to calculate a difference matrix, which is used to modify the solution matrix. The difference matrix is the difference between the constrained target values and the current solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e497d3a-66c6-4dab-9fbe-5af609a3277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are three example expressions where each term is defined inside (), containing a coefficient and factor element.\n",
    "expression1 = \"(0.66*[factor:1|feature:2])-(4.2*[factor:2|feature:4])=0,250\"\n",
    "expression2 = \"(0.35*[factor:0|feature:3])-(2.0*[factor:1|feature:3])-(3.7*[factor:3|feature:4])=0,250\"\n",
    "expression3 = \"(3.2*[factor:2|feature:4])+(1.2*[factor:3|feature:10])+(0.1*[factor:1|feature:3])+(20.0*[factor:4|feature:3])-(10.7*[factor:5|feature:4])=0,250\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe2a7c-1d75-4ab3-8607-b70a5569f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expressions are added with the add_expression function\n",
    "cm.add_expression(expression1)\n",
    "cm.add_expression(expression2)\n",
    "cm.add_expression(expression3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af4b9fe-1acf-47f6-af80-ae16d7a39e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All expressions currently added for the model can be listed using the list_expressions() function\n",
    "cm.list_expressions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8cb6fa-e49e-4708-943f-04c124d4980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An expression can be removed with the .remove_expression and the expression index as found in the list of \n",
    "cm.remove_expression(expression_idx=0)\n",
    "cm.list_expressions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b07766-45d0-49d5-b99b-384dac94d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once all the constraints and expressions have been defined and added. We can tain the constrained model.\n",
    "# When the model is finished training, a new NMF model is availble in the constrained_model object as the constrained_model variable\n",
    "cm.train(max_iterations=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d26dc92-d6ee-402b-93bb-f02ecb35d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results of the constrained model run, as seen in the PMF5 results.\n",
    "cm.display_results()\n",
    "# Show the plot of how Q changes during the constrained model training. Qtype can be 'True', 'Robust', 'aux'.\n",
    "cm.plot_Q(Qtype=\"Aux\") # Qtype: True, Robust, Aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ebf31c-7942-48e4-b17a-d9ca03237af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the constraints factor elements from the constrained model solution.\n",
    "# Note: values may be different than the target valuve or range as expressions and constraints are applied before the matrix update algorithm.\n",
    "cm.evaluate_constraints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182358e-462c-4026-9ba8-bd1cb3e6cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate expression factor elements from the constrained model solution. Includes calculating current value of expressions.\n",
    "cm.evaluate_expressions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2008e3d0-9aa1-4e67-839b-84569aa08476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the profile and contribution graphs of the constrained model for a specified factor index.\n",
    "cm.plot_profile_contributions(factor_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f847bc9-d277-44f7-84e9-cad1ae620ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the factor fingerprint stacked bar graph for the constrained model\n",
    "cm.plot_factor_fingerprints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea5cd9c-75a4-446a-8b4f-4916a99cde20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the g space graph for the constrained model.\n",
    "# Two optional arguments are available: show_base=Boolean, show_delta=Boolean. These default to False.\n",
    "cm.plot_g_space(factor_idx1=1, factor_idx2=2, show_base=True, show_delta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a1050-5acf-415c-bfa3-98300c7f7dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the factor contributions of the constrained model for a specified feature.\n",
    "cm.plot_factor_contributions(feature_idx=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d375ca-a886-4607-a5b4-716bbbfcacba",
   "metadata": {},
   "source": [
    "#### Constrained Model Error Methods\n",
    "\n",
    "The constrained model solution can also be used in the error estimation methods in the same way the NMF model was used. Once the constrained model finds a solution, a new NMF model is available with the constrained model W and H matrices and other parameters. The new constrained NMF model is the ConstrainedModel.constrained_model variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa12b392-ada6-4017-8f11-f7ed300b1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_nmf = cm.constrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9309c6d-7fe7-4b96-951b-bb0ca3747653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Displacement method, passing in the results of the constrained nmf run and the features labels from the data handler.\n",
    "cm_disp = Displacement(nmf=cm_nmf, feature_labels=data_handler.features, model_selected=\"constrained\", features=[0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2b427-f2bd-4821-ba64-cc52846b186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Execute the displacement model\n",
    "cm_disp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68da46d-4746-4adf-9820-7c3f245c65c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show cosntrained model displayment summary\n",
    "cm_disp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3ea892-2025-4abf-87c1-3e6a46f04417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results from the constrained model displacement results\n",
    "factor_i = 1\n",
    "cm_disp.plot_results(factor=factor_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071b3d2e-cf45-463d-929f-ed6dec742d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap input parameters (the same as the base model BS parameters except for the nmf model used.)\n",
    "feature_labels = data_handler.features              # The list of feature names/labels\n",
    "\n",
    "bootstrap_n = 20                                    # The number of bootstrap runs to complete\n",
    "block_size = data_handler.optimal_block             # Calculates an optimal block size from the Politis and White 2004 algorithm (used in PMF5)\n",
    "threshold = 0.6                                     # The r-correlation threshold\n",
    "seed = seed                                         # The random seed used for random selection of the bootstrap blocks.\n",
    "print(f\"Optimal BS block size: {data_handler.optimal_block}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa405d62-3a8c-49e4-b39b-d9387860f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the bootstrap object (changes are to the nmf parameter and the model_selected which is used for labeling in the results)\n",
    "cm_bs = Bootstrap(nmf=cm_nmf, feature_labels=feature_labels, model_selected=\"constrained\", bootstrap_n=bootstrap_n, block_size=block_size, threshold=threshold, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ffb36-6fc6-4340-9651-cec32b5b0898",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Execute the constrained model bootstrap runs\n",
    "cm_bs.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a6ccb7-b4ec-4706-b881-69d7c4a690a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the output summary of all the constrained bootstrap runs.\n",
    "cm_bs.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e5463-dd44-4d2b-a62b-f119f579899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of the constrained bootstrap runs for a specific factor, showing the variability in percentage and concentration for each feature of the specified factor.\n",
    "factor_i = 1\n",
    "cm_bs.plot_results(factor=factor_i)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
